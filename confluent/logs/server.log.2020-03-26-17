[2020-03-26 17:01:49,701] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:01:50,045] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:01:50,089] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:01:50,089] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:01:50,090] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:01:50,091] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:01:50,092] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:01:50,104] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:01:50,114] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,114] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,114] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,114] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,114] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,114] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,115] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,116] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,118] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,122] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:01:50,127] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:01:50,132] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:01:50,134] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:01:50,137] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:01:50,147] INFO Socket connection established, initiating session, client: /127.0.0.1:50849, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:01:50,151] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f1c17b00002, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:01:50,154] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:01:50,323] INFO Cluster ID = e5tdrr37TZu-Vo4_D59YbA (kafka.server.KafkaServer)
[2020-03-26 17:01:50,334] ERROR Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
kafka.common.InconsistentClusterIdException: The Cluster ID e5tdrr37TZu-Vo4_D59YbA doesn't match stored clusterId Some(w0U1yHBOSd2K77g4TFcXSQ) in meta.properties. The broker is trying to join the wrong cluster. Configured zookeeper.connect may be wrong.
	at kafka.server.KafkaServer.startup(KafkaServer.scala:220)
	at io.confluent.support.metrics.SupportedServerStartable.startup(SupportedServerStartable.java:114)
	at io.confluent.support.metrics.SupportedKafka.main(SupportedKafka.java:66)
[2020-03-26 17:01:50,340] INFO shutting down (kafka.server.KafkaServer)
[2020-03-26 17:01:50,342] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:01:50,457] INFO Session: 0x1003f1c17b00002 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:01:50,457] INFO EventThread shut down for session: 0x1003f1c17b00002 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:01:50,459] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:01:50,462] INFO shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:01:50,463] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:01:50,463] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:01:50,463] INFO shutting down (kafka.server.KafkaServer)
[2020-03-26 17:02:08,400] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,401] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,403] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,403] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,405] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:02:08,405] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:02:08,405] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:02:08,405] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:02:08,406] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:02:08,416] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,417] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,417] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,417] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:02:08,417] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:02:08,420] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:02:08,431] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,431] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,431] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,431] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,431] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,431] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,432] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,433] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,434] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,435] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:02:08,447] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:02:08,449] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:02:08,456] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:02:08,469] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:02:08,470] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileSnap)
[2020-03-26 17:02:08,484] INFO Snapshotting: 0x36 to /tmp/zookeeper/version-2/snapshot.36 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:02:08,500] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:02:11,193] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:02:11,547] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:02:11,592] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:02:11,592] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:02:11,593] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:02:11,594] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:02:11,594] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:02:11,608] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:02:11,616] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,616] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,616] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,616] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,616] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,616] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,618] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,620] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:02:11,624] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:02:11,629] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:02:11,634] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:02:11,636] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:02:11,639] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:02:11,649] INFO Socket connection established, initiating session, client: /127.0.0.1:50970, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:02:11,657] INFO Creating new log file: log.37 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:02:11,667] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f209c060000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:02:11,669] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:02:11,847] INFO Cluster ID = e5tdrr37TZu-Vo4_D59YbA (kafka.server.KafkaServer)
[2020-03-26 17:02:11,850] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:02:11,918] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:02:11,926] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:02:11,946] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:02:11,946] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:02:11,947] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:02:11,964] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:02:11,970] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:02:11,977] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[2020-03-26 17:02:11,990] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:02:11,993] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:02:12,287] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:02:12,313] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:02:12,314] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:02:12,329] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,330] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,330] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,330] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,340] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:02:12,377] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:02:12,392] INFO Stat of the created znode at /brokers/ids/0 is: 69,69,1585234932387,1585234932387,1,0,0,72127003327070208,196,0,69
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:02:12,392] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 69 (kafka.zk.KafkaZkClient)
[2020-03-26 17:02:12,436] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,438] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,438] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,443] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:02:12,463] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:12,463] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:12,467] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:12,472] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:02:12,488] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:02:12,489] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:02:12,489] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:02:12,511] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:02:12,523] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:02:12,531] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:02:12,534] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:02:12,534] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:02:12,534] INFO Kafka startTimeMs: 1585234932531 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:02:12,535] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:02:12,619] INFO Creating topic output_final with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:02:12,627] INFO [KafkaApi-0] Auto creation of topic output_final with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:02:12,671] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output_final-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:02:12,741] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:12,745] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-03-26 17:02:12,746] INFO Created log for partition output_final-0 in /tmp/kafka-logs-0/output_final-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:12,747] INFO [Partition output_final-0 broker=0] No checkpointed highwatermark is found for partition output_final-0 (kafka.cluster.Partition)
[2020-03-26 17:02:12,748] INFO [Partition output_final-0 broker=0] Log loaded for partition output_final-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:12,748] INFO [Partition output_final-0 broker=0] output_final-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,043] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:02:13,050] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:02:13,128] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:02:13,133] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,134] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:02:13,134] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,135] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,135] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,135] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,139] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,140] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,140] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,140] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:02:13,141] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,141] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,145] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,145] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,146] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,146] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:02:13,146] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,146] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,150] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,151] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,152] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,152] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:02:13,152] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,152] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,156] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,157] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:02:13,157] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,158] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:02:13,158] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,158] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,161] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,162] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,162] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,162] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:02:13,162] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,162] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,166] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,167] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,167] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,167] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:02:13,167] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,167] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,171] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,171] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,172] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,172] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:02:13,172] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,172] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,175] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,176] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,176] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,176] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:02:13,176] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,177] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,180] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,180] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,181] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,181] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:02:13,181] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,181] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,184] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,185] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,185] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,186] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:02:13,186] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,186] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,189] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,190] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,190] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,190] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:02:13,190] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,190] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,194] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,194] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,194] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,194] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:02:13,195] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,195] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,197] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,198] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,198] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,198] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:02:13,198] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,198] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,201] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,202] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,202] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,202] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:02:13,202] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,202] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,205] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,206] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,206] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,206] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:02:13,206] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,206] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,209] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,210] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,210] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,210] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:02:13,210] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,210] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,213] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,214] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,214] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,214] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:02:13,214] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,215] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,218] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,218] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,219] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,219] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:02:13,219] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,219] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,222] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,223] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,223] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,223] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:02:13,223] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,223] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,226] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,227] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,227] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,227] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:02:13,227] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,227] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,230] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,231] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,231] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,231] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:02:13,231] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,231] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,235] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,235] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,236] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,236] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:02:13,236] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,236] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,240] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,241] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,241] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,241] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:02:13,241] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,241] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,245] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,245] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,246] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,246] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:02:13,246] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,246] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,250] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,251] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,251] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,251] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:02:13,251] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,251] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,255] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,255] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,256] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,256] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:02:13,256] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,256] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,259] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,260] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,260] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,260] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:02:13,260] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,260] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,264] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,264] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,264] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,265] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:02:13,265] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,265] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,268] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,268] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,269] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,269] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:02:13,269] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,269] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,272] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,273] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:02:13,273] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,273] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:02:13,273] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,273] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,276] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,277] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,277] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,277] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:02:13,277] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,277] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,280] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,281] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,281] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,281] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:02:13,281] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,281] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,285] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,285] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,286] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,286] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:02:13,286] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,286] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,289] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,290] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,290] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,290] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:02:13,290] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,290] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,293] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,294] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,294] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,294] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:02:13,294] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,294] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,297] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,298] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,298] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,298] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:02:13,298] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,298] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,301] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,302] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,302] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,302] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:02:13,302] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,302] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,305] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,305] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,306] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,306] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:02:13,306] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,306] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,309] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,309] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,310] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,310] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:02:13,310] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,310] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,313] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,313] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,314] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,314] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:02:13,314] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,314] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,317] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,318] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,318] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,318] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:02:13,318] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,318] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,321] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,322] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,322] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,322] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:02:13,322] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,322] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,326] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,327] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,327] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,327] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:02:13,327] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,327] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,331] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,331] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,332] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,332] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:02:13,332] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,332] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,334] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,335] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:02:13,335] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,335] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:02:13,335] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,335] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,338] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,338] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,339] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,339] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:02:13,339] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,339] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,342] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,342] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,343] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,343] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:02:13,343] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,343] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,346] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,346] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,346] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,346] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:02:13,346] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,347] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,350] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:02:13,350] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:02:13,351] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:02:13,351] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:02:13,351] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:02:13,351] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:02:13,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,353] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,354] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,355] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,356] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,356] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,357] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,357] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,357] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,358] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,361] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,362] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,363] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:02:13,416] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b-9254ce7d-f1c4-428d-9cb2-bca19972f165-StreamThread-1-evaluation.consumer-779ff5ad-3fb9-40f1-8af1-2f62b5b220b4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:13,421] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b generation 1 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:13,426] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:13,593] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Adding new member prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b-9254ce7d-f1c4-428d-9cb2-bca19972f165-StreamThread-2-evaluation.consumer-9af50886-7d98-4366-81bb-758ed9bebae8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:23,485] INFO [GroupCoordinator 0]: Member prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b-9254ce7d-f1c4-428d-9cb2-bca19972f165-StreamThread-1-evaluation.consumer-779ff5ad-3fb9-40f1-8af1-2f62b5b220b4 in group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:23,486] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b generation 2 (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:23,487] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:33,492] INFO [GroupCoordinator 0]: Member prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b-9254ce7d-f1c4-428d-9cb2-bca19972f165-StreamThread-2-evaluation.consumer-9af50886-7d98-4366-81bb-758ed9bebae8 in group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:33,492] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b in state PreparingRebalance with old generation 2 (__consumer_offsets-34) (reason: removing member prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b-9254ce7d-f1c4-428d-9cb2-bca19972f165-StreamThread-2-evaluation.consumer-9af50886-7d98-4366-81bb-758ed9bebae8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:02:33,493] INFO [GroupCoordinator 0]: Group prova_windowstore_4dbeeedd-aea2-456e-b641-39c38f6d563b with generation 3 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:03:02,400] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:03:02,403] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:03:02,411] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:03:02,413] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:03:02,414] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:03:02,414] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:03:02,416] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:03:02,416] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:03:02,416] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:04:10,027] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:04:10,028] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:04:10,028] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:04:10,028] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-26 17:04:10,029] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-26 17:04:10,044] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-26 17:04:10,047] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:04:10,048] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:04:10,048] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:04:10,048] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:04:10,053] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:04:10,054] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:04:10,054] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:04:10,056] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,180] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,180] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,181] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-26 17:04:10,182] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,341] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,341] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,343] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:04:10,344] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:04:10,345] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-26 17:04:10,345] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:04:10,345] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:04:10,345] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:04:10,345] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:04:10,346] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:04:10,346] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,491] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,491] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,492] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,542] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,543] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,543] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:04:10,544] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-03-26 17:04:10,544] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:04:10,544] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:04:10,544] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:04:10,544] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:04:10,545] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:04:10,546] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:04:10,546] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:04:10,546] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,585] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,585] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,586] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,789] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,789] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,790] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,993] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,993] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:10,993] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:11,196] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:11,197] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:11,199] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-03-26 17:04:11,200] INFO Shutting down. (kafka.log.LogManager)
[2020-03-26 17:04:11,220] INFO [ProducerStateManager partition=W1-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:04:11,226] INFO [ProducerStateManager partition=__consumer_offsets-34] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-03-26 17:04:11,236] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-26 17:04:11,241] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:04:11,348] INFO Session: 0x1003f209c060000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:11,348] INFO EventThread shut down for session: 0x1003f209c060000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:04:11,349] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:04:11,350] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:12,264] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:12,264] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:12,264] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:13,265] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:13,265] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:13,265] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:14,266] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:14,266] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:14,267] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-03-26 17:04:14,284] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-03-26 17:04:14,288] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:04:26,383] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,384] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,387] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,387] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,388] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:04:26,388] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:04:26,388] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:04:26,389] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:04:26,389] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:04:26,400] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,400] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,400] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,401] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:04:26,401] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:04:26,403] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:04:26,415] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,415] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,415] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,415] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,415] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,415] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,416] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,418] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,418] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,419] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:04:26,432] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:04:26,434] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:04:26,441] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:04:26,453] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:04:26,456] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:04:26,459] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:04:26,473] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:04:30,171] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:04:30,503] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:04:30,549] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:04:30,549] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:04:30,551] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:04:30,551] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:04:30,552] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:04:30,565] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:04:30,572] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,572] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,572] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,572] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,572] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,572] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,573] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,573] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,573] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,573] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,574] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,576] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:04:30,580] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:04:30,585] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:04:30,590] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:04:30,591] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:04:30,594] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:04:30,605] INFO Socket connection established, initiating session, client: /127.0.0.1:51074, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:04:30,613] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:04:30,622] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f22b6f60000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:04:30,624] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:04:30,831] INFO Cluster ID = obXpmHnxRP-DAGqOPpeupw (kafka.server.KafkaServer)
[2020-03-26 17:04:30,834] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:04:30,880] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:04:30,888] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:04:30,905] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:30,905] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:30,906] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:04:30,922] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:04:30,929] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:04:30,935] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2020-03-26 17:04:30,947] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:04:30,949] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:04:31,237] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:04:31,266] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:04:31,267] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:04:31,281] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,281] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,282] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,282] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,290] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:04:31,307] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:04:31,321] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1585235071316,1585235071316,1,0,0,72127012368941056,196,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:04:31,321] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-26 17:04:31,364] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,366] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,366] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,371] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:04:31,390] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:04:31,391] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:04:31,394] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:04:31,399] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:04:31,415] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:04:31,417] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:04:31,417] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:04:31,438] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:04:31,450] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:04:31,458] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:04:31,461] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:04:31,461] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:04:31,461] INFO Kafka startTimeMs: 1585235071458 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:04:31,462] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:04:46,117] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:04:46,127] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:04:46,185] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:04:46,246] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:04:46,250] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 31 ms (kafka.log.Log)
[2020-03-26 17:04:46,251] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:04:46,252] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:04:46,253] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:04:46,253] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,276] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:05:39,276] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:05:39,283] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:05:39,368] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:05:39,372] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,372] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,373] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,373] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,373] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,373] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,377] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,378] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,378] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,378] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:05:39,378] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,378] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,382] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,383] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,384] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,384] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:05:39,384] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,384] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,387] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,388] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,388] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,388] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:05:39,388] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,389] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,392] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,393] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,393] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,393] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:05:39,393] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,393] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,396] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,397] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,398] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,398] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:05:39,398] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,398] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,402] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,403] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,403] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,403] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:05:39,403] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,403] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,406] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,407] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,407] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,407] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:05:39,407] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,407] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,411] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,411] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,412] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,412] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:05:39,412] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,412] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,415] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,416] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,416] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,416] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:05:39,416] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,417] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,420] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,421] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,421] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,421] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:05:39,421] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,421] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,426] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,426] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,427] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,427] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:05:39,427] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,427] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,431] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,431] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,432] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,432] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:05:39,432] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,432] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,435] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,436] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,436] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,436] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:05:39,436] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,436] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,439] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,440] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,441] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,441] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:05:39,441] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,441] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,444] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,444] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,445] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,445] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:05:39,445] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,445] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,448] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,448] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,449] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,449] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:05:39,449] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,449] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,452] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,453] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,453] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,453] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:05:39,453] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,454] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,457] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,457] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,458] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,458] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:05:39,458] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,458] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,461] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,462] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,462] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,462] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:05:39,462] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,462] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,466] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,466] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,467] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,467] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:05:39,467] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,467] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,470] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,471] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,471] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,471] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:05:39,471] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,471] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,474] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,475] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,475] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,475] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:05:39,475] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,475] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,479] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,479] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,480] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,480] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:05:39,480] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,480] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,485] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,486] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,486] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,486] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:05:39,486] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,486] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,490] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,491] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,491] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,491] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:05:39,491] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,491] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,495] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,495] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,496] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,496] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:05:39,496] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,496] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,500] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,500] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,501] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,501] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:05:39,501] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,501] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,504] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,505] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,505] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,505] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:05:39,505] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,505] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,509] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,509] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,510] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,510] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:05:39,510] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,510] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,513] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,514] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,515] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,515] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:05:39,515] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,515] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,519] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,520] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,520] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,520] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:05:39,520] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,521] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,524] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,525] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,526] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,526] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:05:39,526] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,526] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,530] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,531] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,531] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,531] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:05:39,531] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,531] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,535] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,535] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,536] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,536] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:05:39,536] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,536] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,540] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,540] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,541] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,541] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:05:39,541] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,541] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,544] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,545] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,545] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,545] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:05:39,545] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,545] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,550] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,551] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,551] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,551] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:05:39,551] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,551] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,554] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,555] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,555] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,555] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:05:39,555] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,555] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,559] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,559] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,559] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,559] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:05:39,559] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,560] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,563] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,563] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,564] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,564] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:05:39,564] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,564] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,567] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,567] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,568] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,568] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:05:39,568] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,568] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,570] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,571] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,571] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,571] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:05:39,571] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,571] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,574] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,574] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,575] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,575] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:05:39,575] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,575] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,578] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,578] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,578] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,578] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:05:39,578] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,579] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,582] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,582] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,583] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,583] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:05:39,583] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,583] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,586] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,586] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,587] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,587] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:05:39,587] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,587] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,589] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,590] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,590] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,590] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:05:39,590] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,590] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,593] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,593] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:05:39,599] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,599] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:05:39,599] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,599] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,602] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,603] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,603] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,603] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:05:39,603] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,603] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,606] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,607] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,608] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,609] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,610] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,611] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,612] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,613] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,614] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,615] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:05:39,651] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe in state PreparingRebalance with old generation 0 (__consumer_offsets-49) (reason: Adding new member prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-f987d860-ffbf-4ded-96e0-5a7fc2520eff-StreamThread-2-evaluation.consumer-e404a379-715a-4478-b9bc-29b4e064982f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:05:39,657] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe generation 1 (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:05:39,679] INFO Creating topic prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:05:39,687] INFO Creating topic prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:05:39,689] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:05:39,693] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,694] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,694] INFO Created log for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,694] INFO Creating topic prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:05:39,694] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,695] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 broker=0] Log loaded for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,695] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 broker=0] prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_c6a6f3fc-a25c-48e3-8bd3-ff36439796db-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,699] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:05:39,702] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,703] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:05:39,703] INFO Created log for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,704] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,704] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 broker=0] Log loaded for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,704] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 broker=0] prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_d53ae1ec-8d38-4a08-b7c6-76eb673e5639-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,708] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:05:39,711] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:05:39,712] INFO [Log partition=prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:05:39,712] INFO Created log for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:05:39,713] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,713] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 broker=0] Log loaded for partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:05:39,713] INFO [Partition prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 broker=0] prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-_Store_a70c765c-6147-4cd0-84cd-901c2050028e-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:05:39,726] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:33,351] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 in state PreparingRebalance with old generation 0 (__consumer_offsets-2) (reason: Adding new member prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-95522345-a040-46c9-bc28-6bca06f251f1-StreamThread-1-evaluation.consumer-37303384-a1ca-49de-8e55-b1c55697111b with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:33,353] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 generation 1 (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:33,371] INFO Creating topic prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:07:33,376] INFO Creating topic prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:07:33,379] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:07:33,381] INFO Creating topic prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:07:33,381] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:07:33,382] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:07:33,382] INFO Created log for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:07:33,383] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,383] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 broker=0] Log loaded for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,383] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 broker=0] prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_797dc3ea-fac0-48a4-9333-ad357ea44bc4-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:07:33,387] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:07:33,390] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:07:33,391] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:07:33,391] INFO Created log for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:07:33,392] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,392] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 broker=0] Log loaded for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,392] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 broker=0] prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_e234fe54-80d3-487d-81b7-4fd53464731d-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:07:33,396] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:07:33,399] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:07:33,400] INFO [Log partition=prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:07:33,400] INFO Created log for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:07:33,401] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,401] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 broker=0] Log loaded for partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:07:33,401] INFO [Partition prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 broker=0] prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-_Store_dc280707-87a7-4129-8b93-2ac52eaa400c-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:07:33,410] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:37,843] INFO [GroupCoordinator 0]: Member prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-f987d860-ffbf-4ded-96e0-5a7fc2520eff-StreamThread-1-evaluation.consumer-ddfae0e5-e4c1-4975-b69d-cbfab94dfe49 in group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:37,843] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe in state PreparingRebalance with old generation 1 (__consumer_offsets-49) (reason: removing member prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-f987d860-ffbf-4ded-96e0-5a7fc2520eff-StreamThread-1-evaluation.consumer-ddfae0e5-e4c1-4975-b69d-cbfab94dfe49 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:37,844] INFO [GroupCoordinator 0]: Member prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe-f987d860-ffbf-4ded-96e0-5a7fc2520eff-StreamThread-2-evaluation.consumer-e404a379-715a-4478-b9bc-29b4e064982f in group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:37,845] INFO [GroupCoordinator 0]: Group prova_windowstore_82783461-bdfd-4bb0-8981-8292a66004fe with generation 2 is now empty (__consumer_offsets-49) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:55,213] INFO [GroupCoordinator 0]: Member prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-95522345-a040-46c9-bc28-6bca06f251f1-StreamThread-1-evaluation.consumer-37303384-a1ca-49de-8e55-b1c55697111b in group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:55,213] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 in state PreparingRebalance with old generation 1 (__consumer_offsets-2) (reason: removing member prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-95522345-a040-46c9-bc28-6bca06f251f1-StreamThread-1-evaluation.consumer-37303384-a1ca-49de-8e55-b1c55697111b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:55,214] INFO [GroupCoordinator 0]: Member prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7-95522345-a040-46c9-bc28-6bca06f251f1-StreamThread-2-evaluation.consumer-eba35e99-743b-47a7-8197-9e31b9777178 in group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:07:55,214] INFO [GroupCoordinator 0]: Group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 with generation 2 is now empty (__consumer_offsets-2) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:08:51,561] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-6472dd77-4d43-41fb-a88c-352ea8afef81-StreamThread-2-evaluation.consumer-9fec9901-c55a-465a-95cb-b309523e26e9 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:08:51,563] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:08:51,579] INFO Creating topic prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:08:51,583] INFO Creating topic prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:08:51,587] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:08:51,588] INFO Creating topic prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:08:51,590] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:08:51,590] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:08:51,591] INFO Created log for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:08:51,591] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,591] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 broker=0] Log loaded for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,591] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 broker=0] prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_a7951ec8-8cdb-4c22-b58e-dfbf632dee66-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:08:51,594] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:08:51,597] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:08:51,598] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:08:51,598] INFO Created log for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:08:51,600] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,600] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 broker=0] Log loaded for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,600] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 broker=0] prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_b880822b-adc9-456e-bd72-2a5b00a3535f-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:08:51,604] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:08:51,606] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:08:51,607] INFO [Log partition=prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:08:51,607] INFO Created log for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:08:51,608] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,608] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 broker=0] Log loaded for partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:08:51,608] INFO [Partition prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 broker=0] prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-_Store_18b92f10-a62f-499a-ab3c-ea8007c71362-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:08:51,617] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:09:19,635] INFO [GroupCoordinator 0]: Member prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-6472dd77-4d43-41fb-a88c-352ea8afef81-StreamThread-2-evaluation.consumer-9fec9901-c55a-465a-95cb-b309523e26e9 in group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:09:19,636] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-6472dd77-4d43-41fb-a88c-352ea8afef81-StreamThread-2-evaluation.consumer-9fec9901-c55a-465a-95cb-b309523e26e9 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:09:19,636] INFO [GroupCoordinator 0]: Member prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881-6472dd77-4d43-41fb-a88c-352ea8afef81-StreamThread-1-evaluation.consumer-d70874ee-bab0-497b-8994-2912d627226c in group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:09:19,637] INFO [GroupCoordinator 0]: Group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:13:39,267] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da in state PreparingRebalance with old generation 0 (__consumer_offsets-28) (reason: Adding new member prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-984151eb-1d7d-4ee1-80c9-ac23b16498a4-StreamThread-1-evaluation.consumer-473f8361-00ab-4771-9394-aba0c3b5ebf4 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:13:39,268] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da generation 1 (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:13:39,281] INFO Creating topic prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:13:39,286] INFO Creating topic prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:13:39,290] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:13:39,290] INFO Creating topic prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:13:39,292] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:13:39,293] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:13:39,293] INFO Created log for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:13:39,293] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,293] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 broker=0] Log loaded for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,293] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 broker=0] prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_07446f1b-6f67-4081-a86a-910f3ac8dfd7-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:13:39,296] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:13:39,299] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:13:39,299] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:13:39,299] INFO Created log for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:13:39,300] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,300] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 broker=0] Log loaded for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,300] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 broker=0] prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_52a40d7d-dd4b-4bc6-a58a-a5a3da664dd9-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:13:39,303] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:13:39,305] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:13:39,305] INFO [Log partition=prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:13:39,306] INFO Created log for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:13:39,306] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,306] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 broker=0] Log loaded for partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:13:39,306] INFO [Partition prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 broker=0] prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-_Store_b6881df1-5bc5-4276-b22e-d3eb02a3cb8b-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:13:39,314] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:14:31,398] INFO [GroupMetadataManager brokerId=0] Group prova_windowstore_2ebbad58-be4e-415d-97a2-4222a2332fc7 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:14:31,399] INFO [GroupMetadataManager brokerId=0] Group prova_windowstore_0e7259d2-62ac-4324-b920-4ac581608881 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:14:31,400] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:15:46,416] INFO [GroupCoordinator 0]: Member prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-984151eb-1d7d-4ee1-80c9-ac23b16498a4-StreamThread-2-evaluation.consumer-5d46a3e0-3348-4ba8-990c-af343ce1072e in group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:15:46,416] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da in state PreparingRebalance with old generation 1 (__consumer_offsets-28) (reason: removing member prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-984151eb-1d7d-4ee1-80c9-ac23b16498a4-StreamThread-2-evaluation.consumer-5d46a3e0-3348-4ba8-990c-af343ce1072e on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:15:46,428] INFO [GroupCoordinator 0]: Member prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da-984151eb-1d7d-4ee1-80c9-ac23b16498a4-StreamThread-1-evaluation.consumer-473f8361-00ab-4771-9394-aba0c3b5ebf4 in group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:15:46,428] INFO [GroupCoordinator 0]: Group prova_windowstore_f7d02e24-11c5-4db8-b8cd-e8770b1ea3da with generation 2 is now empty (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:17:48,679] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d in state PreparingRebalance with old generation 0 (__consumer_offsets-28) (reason: Adding new member prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-400b5ed6-6294-41c7-844e-48dc0226c641-StreamThread-2-evaluation.consumer-b240d55f-683f-4eb1-a11f-473ef97a60c7 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:17:48,680] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d generation 1 (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:17:48,693] INFO Creating topic prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:17:48,696] INFO Creating topic prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:17:48,699] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:17:48,700] INFO Creating topic prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:17:48,702] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:17:48,703] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:17:48,703] INFO Created log for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:17:48,704] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,704] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 broker=0] Log loaded for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,704] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 broker=0] prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_4cce49ec-dfcd-49c6-9565-50de96564f46-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:17:48,708] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:17:48,710] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:17:48,711] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:17:48,711] INFO Created log for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:17:48,712] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,712] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 broker=0] Log loaded for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,712] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 broker=0] prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_b91bd1c5-d200-4046-a549-17da8381aebb-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:17:48,715] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:17:48,717] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:17:48,718] INFO [Log partition=prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:17:48,718] INFO Created log for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:17:48,719] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,719] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 broker=0] Log loaded for partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:17:48,719] INFO [Partition prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 broker=0] prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d-_Store_8c3902a4-0a54-42a2-98fc-fe9b9c5024c8-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:17:48,726] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_15a2fc54-fcd3-4742-8bd9-0a8fe78ed11d for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:01,536] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:18:01,537] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:18:01,537] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:18:01,537] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-26 17:18:01,538] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-26 17:18:01,551] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-26 17:18:01,553] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:18:01,553] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:18:01,553] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:18:01,554] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:18:01,559] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:18:01,559] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:18:01,560] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:18:01,562] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,651] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,651] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,652] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-26 17:18:01,652] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,830] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,830] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,832] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:18:01,833] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:18:01,833] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-26 17:18:01,833] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:18:01,833] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:18:01,834] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:18:01,834] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:18:01,835] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:01,835] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,891] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,891] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:01,892] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,060] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,060] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,061] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:02,062] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-03-26 17:18:02,062] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:18:02,062] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:18:02,062] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:18:02,063] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:18:02,064] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:18:02,065] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:18:02,065] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:18:02,065] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,132] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,132] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,133] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,284] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,284] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,284] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,488] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,488] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,488] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,510] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,510] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:02,513] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-03-26 17:18:02,514] INFO Shutting down. (kafka.log.LogManager)
[2020-03-26 17:18:02,522] INFO [ProducerStateManager partition=__consumer_offsets-22] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-03-26 17:18:02,536] INFO [ProducerStateManager partition=__consumer_offsets-49] Writing producer snapshot at offset 4 (kafka.log.ProducerStateManager)
[2020-03-26 17:18:02,537] INFO [ProducerStateManager partition=__consumer_offsets-28] Writing producer snapshot at offset 5 (kafka.log.ProducerStateManager)
[2020-03-26 17:18:02,540] INFO [ProducerStateManager partition=W1-0] Writing producer snapshot at offset 11 (kafka.log.ProducerStateManager)
[2020-03-26 17:18:02,542] INFO [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3 (kafka.log.ProducerStateManager)
[2020-03-26 17:18:02,558] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-26 17:18:02,562] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:18:02,666] INFO Session: 0x1003f22b6f60000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:02,666] INFO EventThread shut down for session: 0x1003f22b6f60000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:18:02,667] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:18:02,667] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:02,926] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:02,926] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:02,926] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:03,926] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:03,926] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:03,927] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:04,928] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:04,928] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:04,929] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-03-26 17:18:04,939] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-03-26 17:18:04,941] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:18:25,546] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,548] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,551] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,551] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,552] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:18:25,552] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:18:25,552] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:18:25,552] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:18:25,553] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:18:25,565] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,565] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,565] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,565] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:18:25,565] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:18:25,568] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:18:25,590] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,590] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,590] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,590] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,590] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,590] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,592] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,594] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,594] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,596] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:18:25,609] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:18:25,611] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:18:25,619] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:18:25,631] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:18:25,635] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:18:25,638] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:18:25,651] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:18:29,521] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:18:29,905] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:18:29,951] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:18:29,951] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:18:29,952] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:18:29,953] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:18:29,954] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:18:29,968] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:18:29,975] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,975] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,975] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,975] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,975] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,975] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,976] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,978] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:18:29,982] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:18:29,987] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:18:29,991] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:18:29,993] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:18:29,996] INFO Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:18:30,006] INFO Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:51793, server: localhost/0:0:0:0:0:0:0:1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:18:30,014] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:18:30,023] INFO Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, sessionid = 0x1003f2f84fb0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:18:30,025] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:18:30,241] INFO Cluster ID = NiVzKMH8Tv-QeruHPWyKYQ (kafka.server.KafkaServer)
[2020-03-26 17:18:30,244] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:18:30,292] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:18:30,299] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:18:30,317] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:30,317] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:30,317] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:18:30,333] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:18:30,339] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:18:30,345] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2020-03-26 17:18:30,357] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:18:30,359] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:18:30,643] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:18:30,668] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:18:30,669] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:18:30,684] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,684] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,684] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,685] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,694] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:18:30,711] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:18:30,725] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1585235910721,1585235910721,1,0,0,72127067364982784,196,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:18:30,725] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-26 17:18:30,768] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,770] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,770] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,774] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:18:30,794] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:30,795] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:30,799] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:30,804] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:18:30,820] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:18:30,821] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:18:30,821] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:18:30,842] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:18:30,854] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:18:30,862] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:18:30,865] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:18:30,865] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:18:30,865] INFO Kafka startTimeMs: 1585235910863 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:18:30,866] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:18:52,323] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:18:52,323] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:18:52,338] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:18:52,494] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:18:52,557] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,561] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 30 ms (kafka.log.Log)
[2020-03-26 17:18:52,562] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,563] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,565] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,565] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,575] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,576] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,576] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,576] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:18:52,576] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,576] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,580] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,580] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,581] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,581] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:18:52,581] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,581] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,584] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,585] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,585] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,585] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:18:52,585] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,585] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,589] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,589] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,590] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,590] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:18:52,590] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,590] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,593] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,593] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,594] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,594] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:18:52,594] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,594] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,597] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,598] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,598] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,598] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:18:52,598] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,598] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,602] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,603] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,603] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,603] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:18:52,603] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,603] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,606] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,607] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,607] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,607] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:18:52,607] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,608] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,611] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,611] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,612] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,612] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:18:52,612] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,612] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,615] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,616] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,616] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,616] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:18:52,616] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,616] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,620] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,620] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,621] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,621] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:18:52,621] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,621] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,624] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,625] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,625] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,625] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:18:52,625] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,625] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,629] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,629] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,630] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,630] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:18:52,630] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,630] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,633] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,634] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,634] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,634] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:18:52,634] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,634] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,638] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,639] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:18:52,639] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,639] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:18:52,639] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,639] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,642] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,643] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,643] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,643] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:18:52,643] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,643] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,648] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,648] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,649] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,649] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:18:52,649] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,649] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,652] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,653] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,653] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,653] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:18:52,653] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,653] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,657] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,657] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,657] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,657] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:18:52,658] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,658] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,661] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,661] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,662] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,662] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:18:52,662] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,662] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,667] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,667] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,668] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,668] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:18:52,668] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,668] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,671] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,672] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,672] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,672] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:18:52,672] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,672] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,676] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,676] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,676] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,676] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:18:52,677] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,677] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,680] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,680] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,681] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,681] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:18:52,681] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,681] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,685] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,685] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,685] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,685] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:18:52,686] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,686] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,689] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,689] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,690] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,690] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:18:52,690] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,690] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,693] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,694] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,694] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,694] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:18:52,695] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,695] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,698] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,698] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,699] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,699] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:18:52,699] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,699] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,702] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,702] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,703] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,703] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:18:52,703] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,703] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,706] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,706] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,707] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,707] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:18:52,707] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,707] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,710] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,711] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,711] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,711] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:18:52,711] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,711] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,715] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,715] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,716] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,716] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:18:52,716] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,716] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,719] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,720] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,720] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,720] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:18:52,720] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,720] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,723] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,724] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,724] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,724] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:18:52,724] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,724] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,727] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,728] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,728] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,728] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:18:52,728] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,728] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,731] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,732] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,732] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,732] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:18:52,733] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,733] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,735] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,736] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,736] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,736] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:18:52,736] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,736] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,739] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,740] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,740] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,740] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:18:52,740] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,740] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,743] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,744] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,744] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,744] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:18:52,744] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,744] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,747] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,748] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,748] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,748] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:18:52,748] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,748] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,751] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,752] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,752] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,752] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:18:52,752] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,752] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,755] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,756] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,756] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,756] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:18:52,756] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,756] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,759] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,759] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,760] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,760] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:18:52,760] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,760] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,763] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,763] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,764] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,764] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:18:52,764] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,764] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,767] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,768] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,768] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,768] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:18:52,768] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,768] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,771] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,771] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:18:52,772] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,772] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:18:52,772] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,772] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,774] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,775] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,775] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,775] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:18:52,775] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,775] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,778] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,778] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,778] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,778] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:18:52,778] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,778] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,781] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:18:52,782] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:18:52,782] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:18:52,782] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:18:52,782] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:18:52,782] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:18:52,790] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,791] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,792] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,793] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,794] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,795] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,796] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,796] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,796] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,797] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,798] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,799] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,800] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,800] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,801] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,802] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,803] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,804] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,804] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:18:52,869] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 in state PreparingRebalance with old generation 0 (__consumer_offsets-5) (reason: Adding new member prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932-872d8b23-c87d-43a1-82c1-27eb762b2124-StreamThread-2-evaluation.consumer-6f6c165a-ae80-4be4-89fd-b950d310ae2c with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:52,876] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 generation 1 (__consumer_offsets-5) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:18:52,882] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:02,931] INFO [GroupCoordinator 0]: Member prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932-872d8b23-c87d-43a1-82c1-27eb762b2124-StreamThread-2-evaluation.consumer-6f6c165a-ae80-4be4-89fd-b950d310ae2c in group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:02,932] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 in state PreparingRebalance with old generation 1 (__consumer_offsets-5) (reason: removing member prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932-872d8b23-c87d-43a1-82c1-27eb762b2124-StreamThread-2-evaluation.consumer-6f6c165a-ae80-4be4-89fd-b950d310ae2c on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:02,933] INFO [GroupCoordinator 0]: Member prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932-872d8b23-c87d-43a1-82c1-27eb762b2124-StreamThread-1-evaluation.consumer-a9495f11-281d-4415-95a4-62b524986c5c in group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:02,933] INFO [GroupCoordinator 0]: Group prova_windowstore_5ced158a-de6f-4a57-8e77-a59460b97932 with generation 2 is now empty (__consumer_offsets-5) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:13,139] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:19:13,144] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:19:13,153] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:19:13,156] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:19:13,157] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:19:13,158] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:19:13,160] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:19:13,160] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:19:13,160] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:19:48,843] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-97d2b67a-dbd8-4bb5-9c46-1e7e10449ac2-StreamThread-1-evaluation.consumer-6eede605-376a-4c3c-8209-ce06be66c71f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:48,845] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:19:48,866] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:19:48,876] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:19:48,877] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:19:48,880] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:19:48,880] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:19:48,881] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:19:48,882] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,882] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,882] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:19:48,883] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:19:48,886] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:19:48,889] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:19:48,890] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:19:48,890] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:19:48,891] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,892] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,892] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:19:48,895] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:19:48,898] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:19:48,898] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:19:48,899] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:19:48,900] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,900] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:19:48,900] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:19:48,912] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:18,393] INFO Creating topic output_final with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:20:18,397] INFO [KafkaApi-0] Auto creation of topic output_final with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:20:18,404] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output_final-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:20:18,407] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:20:18,408] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:20:18,409] INFO Created log for partition output_final-0 in /tmp/kafka-logs-0/output_final-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:20:18,409] INFO [Partition output_final-0 broker=0] No checkpointed highwatermark is found for partition output_final-0 (kafka.cluster.Partition)
[2020-03-26 17:20:18,409] INFO [Partition output_final-0 broker=0] Log loaded for partition output_final-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:20:18,410] INFO [Partition output_final-0 broker=0] output_final-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:20:18,423] INFO [GroupCoordinator 0]: Preparing to rebalance group 71b53bb8-0ba7-42bb-b822-146b1698d448 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member your_client_idbdd465f9-9917-437e-bb5b-9a5cc1d4e811-7232b0c0-4c5d-4e0c-898a-4a1911a615dd with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:18,424] INFO [GroupCoordinator 0]: Stabilized group 71b53bb8-0ba7-42bb-b822-146b1698d448 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:18,510] INFO [GroupCoordinator 0]: Assignment received from leader for group 71b53bb8-0ba7-42bb-b822-146b1698d448 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:53,458] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:20:53,458] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:20:53,458] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:20:53,459] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-26 17:20:53,460] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-26 17:20:53,473] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-26 17:20:53,476] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:20:53,477] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:20:53,477] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:20:53,477] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:20:53,483] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:20:53,484] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:20:53,485] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:20:53,486] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,618] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,618] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,618] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-26 17:20:53,619] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,711] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,711] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,712] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:20:53,713] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:20:53,713] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-26 17:20:53,713] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:20:53,713] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:20:53,713] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:20:53,713] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:20:53,714] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:53,714] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,828] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,828] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:53,829] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,020] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,020] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,020] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:20:54,021] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-03-26 17:20:54,021] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:20:54,021] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:20:54,021] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:20:54,022] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:20:54,023] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:20:54,023] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:20:54,023] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:20:54,023] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,185] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,185] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,186] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,221] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,221] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,222] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,321] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,321] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,321] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,520] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,520] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:20:54,522] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-03-26 17:20:54,523] INFO Shutting down. (kafka.log.LogManager)
[2020-03-26 17:20:54,537] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 7 (kafka.log.ProducerStateManager)
[2020-03-26 17:20:54,547] INFO [ProducerStateManager partition=W1-0] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:20:54,548] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:20:54,552] INFO [ProducerStateManager partition=__consumer_offsets-5] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:20:54,564] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-26 17:20:54,568] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:20:54,674] INFO Session: 0x1003f2f84fb0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:20:54,674] INFO EventThread shut down for session: 0x1003f2f84fb0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:20:54,675] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:20:54,675] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:54,682] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:54,682] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:54,682] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:55,686] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:55,686] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:55,686] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:56,686] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:56,686] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:20:56,687] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-03-26 17:20:56,701] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-03-26 17:20:56,704] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:21:06,671] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,672] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,675] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,675] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,677] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:06,677] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:06,677] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:06,677] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:21:06,678] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:21:06,689] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,689] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,689] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,689] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:06,689] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:21:06,692] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:06,703] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,703] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,703] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,704] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,704] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,704] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,705] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,706] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,706] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,708] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:06,721] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:21:06,723] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:06,731] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:06,744] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:21:06,747] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:06,749] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:06,762] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:21:16,616] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:21:16,951] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:16,993] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:21:16,993] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:16,995] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:21:16,995] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:21:16,996] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:21:17,009] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:17,016] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,016] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,016] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,016] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,016] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,016] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,017] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,018] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,020] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:17,024] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:21:17,029] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:21:17,034] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:17,035] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:17,038] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:17,049] INFO Socket connection established, initiating session, client: /127.0.0.1:52086, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:17,057] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:21:17,070] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f31fa4d0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:17,072] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:17,280] INFO Cluster ID = iJyAKO56RoKdL3y5RWeckw (kafka.server.KafkaServer)
[2020-03-26 17:21:17,284] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:21:17,327] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:17,334] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:17,355] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:17,355] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:17,355] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:17,373] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:21:17,380] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:21:17,386] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2020-03-26 17:21:17,398] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:21:17,401] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:21:17,700] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:21:17,727] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:21:17,728] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:21:17,743] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,744] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,744] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,745] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,754] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:17,771] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:17,785] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1585236077780,1585236077780,1,0,0,72127077923225600,196,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:17,786] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:17,830] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,832] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,832] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,837] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:17,857] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:17,858] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:17,861] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:17,867] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:21:17,885] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:17,886] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:17,887] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:17,906] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:17,919] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:17,926] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:21:17,929] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:17,929] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:17,929] INFO Kafka startTimeMs: 1585236077927 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:17,930] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:21:17,989] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:17,989] INFO Creating topic output_final with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:18,001] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:18,001] INFO [KafkaApi-0] Auto creation of topic output_final with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:18,030] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:18,035] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:18,060] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0, output_final-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:18,133] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,136] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 29 ms (kafka.log.Log)
[2020-03-26 17:21:18,138] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,138] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,139] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,139] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,148] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,148] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,149] INFO Created log for partition output_final-0 in /tmp/kafka-logs-0/output_final-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,149] INFO [Partition output_final-0 broker=0] No checkpointed highwatermark is found for partition output_final-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,149] INFO [Partition output_final-0 broker=0] Log loaded for partition output_final-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,149] INFO [Partition output_final-0 broker=0] output_final-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,200] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:18,205] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,206] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,207] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,208] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,208] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,208] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,215] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,215] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,216] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,216] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:21:18,216] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,216] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,220] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,222] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,222] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,222] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:21:18,222] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,222] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,227] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,228] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,228] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,228] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:21:18,228] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,229] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,233] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,233] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,234] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,234] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:21:18,234] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,235] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,240] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,240] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,241] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,241] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:21:18,242] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,242] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,249] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,250] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,250] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,250] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:21:18,251] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,251] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,255] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,256] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,256] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,256] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:21:18,256] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,256] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,261] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,262] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,262] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,262] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:21:18,262] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,262] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,267] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,267] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,268] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,268] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:21:18,268] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,268] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,272] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,272] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,273] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,273] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:21:18,273] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,273] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,276] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,277] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,277] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,277] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:21:18,277] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,277] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,281] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,282] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,283] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,283] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:21:18,283] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,283] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,286] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,287] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,288] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,288] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:21:18,288] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,288] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,292] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,293] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,293] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,294] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:21:18,294] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,294] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,297] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,298] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,298] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,299] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:21:18,299] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,299] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,302] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,302] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,303] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,303] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:21:18,303] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,303] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,306] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,307] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,307] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,307] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:21:18,307] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,307] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,311] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,311] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,312] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,312] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:21:18,312] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,312] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,315] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,316] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,316] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,316] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:21:18,316] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,316] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,320] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,320] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,321] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,321] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:21:18,321] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,321] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,324] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,324] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,325] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,325] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:21:18,325] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,325] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,328] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,328] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,329] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,329] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:21:18,329] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,329] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,332] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,332] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,333] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,333] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:21:18,333] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,333] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,336] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,336] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,336] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,336] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:21:18,337] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,337] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,340] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,340] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,341] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,341] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:21:18,341] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,341] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,344] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,344] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,345] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,345] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:21:18,345] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,345] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,348] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,349] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,349] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,349] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:21:18,349] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,349] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,352] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,353] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,353] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,353] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:21:18,353] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,353] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,357] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,358] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,358] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,358] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:21:18,358] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,359] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,363] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,363] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,364] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,364] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:21:18,364] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,364] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,367] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,367] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,367] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,367] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:21:18,368] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,368] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,370] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,371] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,371] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,371] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:21:18,371] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,371] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,375] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,375] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,375] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,375] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:21:18,376] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,376] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,378] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,379] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,379] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,379] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:21:18,379] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,379] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,382] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,383] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,383] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,383] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:21:18,383] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,383] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,386] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,386] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,387] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,387] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:21:18,387] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,387] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,390] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,390] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:18,390] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,390] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:21:18,391] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,391] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,393] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,394] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,394] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,394] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:21:18,394] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,394] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,397] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,398] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,398] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,398] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:21:18,398] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,398] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,401] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,402] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,402] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,402] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:21:18,402] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,402] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,405] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,406] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,406] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,406] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:21:18,407] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,407] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,410] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,411] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,411] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,411] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:21:18,411] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,411] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,414] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,415] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,415] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,415] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:21:18,415] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,416] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,419] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,419] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,419] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,420] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:21:18,420] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,420] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,423] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,424] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,424] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,424] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:21:18,424] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,424] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,427] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,428] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,428] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,428] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:21:18,428] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,428] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,431] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,432] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,432] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,432] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:21:18,432] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,432] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,435] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,436] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,436] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,436] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:21:18,436] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,436] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,439] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,440] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,440] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,440] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:21:18,440] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,440] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,443] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,444] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,445] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,446] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,446] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,446] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,447] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,447] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,447] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,448] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,449] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:18,541] INFO [GroupCoordinator 0]: Preparing to rebalance group 71b53bb8-0ba7-42bb-b822-146b1698d448 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member your_client_idbdd465f9-9917-437e-bb5b-9a5cc1d4e811-07aa55f6-4138-4864-a94c-3a4d24d34cb3 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,541] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-97d2b67a-dbd8-4bb5-9c46-1e7e10449ac2-StreamThread-1-evaluation.consumer-76446ee7-521d-4ab3-a130-34130cde36aa with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,546] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,548] INFO [GroupCoordinator 0]: Stabilized group 71b53bb8-0ba7-42bb-b822-146b1698d448 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,550] INFO [GroupCoordinator 0]: Assignment received from leader for group 71b53bb8-0ba7-42bb-b822-146b1698d448 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,556] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:18,574] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: Adding new member prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-97d2b67a-dbd8-4bb5-9c46-1e7e10449ac2-StreamThread-2-evaluation.consumer-a64e8901-4991-4753-a061-888dafc2480f with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,575] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:18,576] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:18,579] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,580] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:18,580] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,581] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,581] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,581] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,584] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:18,586] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:18,589] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,590] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,590] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,591] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,591] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,591] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,596] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:18,598] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:18,599] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:18,599] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:18,599] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,600] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:18,600] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:18,606] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba generation 2 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:18,612] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:26,333] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:21:26,335] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:26,335] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:26,335] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-26 17:21:26,336] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-26 17:21:26,356] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-26 17:21:26,359] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:26,360] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:26,360] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:26,360] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:21:26,367] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:21:26,367] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:21:26,368] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:21:26,369] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,431] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,431] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,432] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-26 17:21:26,432] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,528] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,528] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,530] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:26,530] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:21:26,531] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-26 17:21:26,531] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:26,532] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:26,532] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:26,532] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:26,533] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:26,533] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,653] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,653] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,654] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,854] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,854] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,854] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:26,855] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-03-26 17:21:26,855] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:26,855] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:26,855] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:26,855] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:26,856] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:26,857] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:21:26,857] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:21:26,857] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,984] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,984] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:26,984] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,079] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,079] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,080] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,258] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,258] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,259] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,279] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,279] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:27,283] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-03-26 17:21:27,283] INFO Shutting down. (kafka.log.LogManager)
[2020-03-26 17:21:27,300] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:21:27,308] INFO [ProducerStateManager partition=W1-0] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-03-26 17:21:27,309] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 2 (kafka.log.ProducerStateManager)
[2020-03-26 17:21:27,327] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-26 17:21:27,332] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:27,439] INFO Session: 0x1003f31fa4d0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:27,439] INFO EventThread shut down for session: 0x1003f31fa4d0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:27,440] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:27,440] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:28,385] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:28,385] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:28,385] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:29,389] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:29,389] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:29,389] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:30,392] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:30,392] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:30,394] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-03-26 17:21:30,411] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-03-26 17:21:30,413] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:21:38,064] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,065] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,067] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,067] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,069] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:38,069] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:38,069] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:38,069] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:21:38,070] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:21:38,080] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,080] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,081] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,081] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:38,081] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:21:38,084] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:38,095] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,095] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,095] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,095] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,095] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,095] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,096] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,097] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,098] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,098] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,099] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:38,111] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:21:38,113] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:38,121] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:38,133] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:21:38,136] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:38,139] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:38,152] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:21:39,872] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:21:40,204] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:40,251] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:21:40,251] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:40,253] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:21:40,253] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:21:40,254] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:21:40,268] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:40,276] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,276] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,276] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,276] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,276] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,276] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,277] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,278] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,280] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:40,284] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:21:40,289] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:21:40,294] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:40,296] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:40,299] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:40,310] INFO Socket connection established, initiating session, client: /127.0.0.1:52239, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:40,318] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:21:40,327] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f3274ea0000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:40,329] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:40,547] INFO Cluster ID = VOCkjrFWS_a9niMoiUGRgg (kafka.server.KafkaServer)
[2020-03-26 17:21:40,551] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:21:40,597] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:40,604] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:21:40,623] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:40,623] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:40,624] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:40,642] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:21:40,648] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:21:40,655] INFO Logs loading complete in 6 ms. (kafka.log.LogManager)
[2020-03-26 17:21:40,668] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:21:40,670] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:21:40,975] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:21:40,996] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:21:40,997] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:21:41,013] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,013] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,014] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,014] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,023] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:41,039] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:41,054] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1585236101049,1585236101049,1,0,0,72127079980335104,196,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:41,054] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:41,099] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,101] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,101] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,106] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:21:41,127] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:41,128] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:41,132] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,137] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:21:41,153] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:41,155] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:41,155] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:41,176] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:41,189] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:41,197] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:21:41,200] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:41,200] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:41,200] INFO Kafka startTimeMs: 1585236101197 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:21:41,201] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:21:41,542] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:41,557] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:41,692] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:41,755] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,759] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-03-26 17:21:41,760] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,761] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,762] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,762] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,772] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,773] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,773] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,773] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:21:41,773] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,773] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,777] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,778] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,778] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,778] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:21:41,778] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,778] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,782] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,782] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,783] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,783] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:21:41,783] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,783] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,786] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,787] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,787] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,787] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:21:41,787] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,787] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,790] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,791] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,791] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,791] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:21:41,791] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,791] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,795] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,795] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,796] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,796] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:21:41,796] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,796] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,799] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,800] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,801] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,801] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:21:41,801] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,801] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,805] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,805] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,805] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,806] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:21:41,806] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,806] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,809] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,809] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,810] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,810] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:21:41,810] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,810] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,813] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,813] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,814] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,814] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:21:41,814] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,814] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,817] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,817] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,818] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,818] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:21:41,818] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,818] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,821] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,821] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,822] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,822] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:21:41,822] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,822] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,825] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,825] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,826] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,826] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:21:41,826] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,826] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,829] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,830] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,830] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,830] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:21:41,830] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,830] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,834] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,834] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,834] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,835] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:21:41,835] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,835] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,838] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,838] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,839] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,839] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:21:41,839] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,839] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,842] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,842] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,843] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,843] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:21:41,843] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,843] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,846] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,846] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,847] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,847] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:21:41,847] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,847] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,851] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,852] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:41,852] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,852] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:21:41,852] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,852] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,853] INFO Creating topic output_final with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:41,856] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,856] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,856] INFO [KafkaApi-0] Auto creation of topic output_final with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:41,856] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,856] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:21:41,856] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,857] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,861] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,861] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,862] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,862] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:21:41,862] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,862] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,866] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,866] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,867] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,867] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:21:41,867] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,867] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,871] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,871] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,871] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,872] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:21:41,872] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,872] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,875] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,875] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,875] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,875] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:21:41,875] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,876] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,879] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,879] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,880] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,880] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:21:41,880] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,880] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,883] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,884] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,884] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,884] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:21:41,884] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,884] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,888] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,889] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,889] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,889] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:21:41,889] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,889] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,892] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,893] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,893] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,893] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:21:41,893] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,894] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,897] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,897] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,898] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,898] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:21:41,898] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,898] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,901] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,902] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,902] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,902] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:21:41,902] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,902] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,906] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,906] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,907] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,907] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:21:41,907] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,907] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,910] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,910] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,911] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,911] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:21:41,911] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,911] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,914] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,914] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,914] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,914] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:21:41,914] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,914] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,917] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,918] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,918] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,918] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:21:41,918] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,918] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,921] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,921] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,922] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,922] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:21:41,922] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,922] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,925] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,925] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,926] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,926] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:21:41,926] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,926] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,929] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,930] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,930] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,930] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:21:41,930] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,930] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,933] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,934] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,934] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,934] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:21:41,934] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,934] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,938] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,938] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,939] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,939] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:21:41,939] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,939] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,940] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:41,943] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:21:41,943] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,944] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,945] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,945] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:21:41,945] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,945] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,948] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,949] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,949] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,949] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:21:41,949] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,949] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,956] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,956] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,956] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,956] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:21:41,957] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,957] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,959] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,960] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,960] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,960] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:21:41,960] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,960] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,963] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,964] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,964] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,964] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:21:41,964] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,964] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,967] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,968] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,968] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,968] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:21:41,968] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,968] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,971] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,972] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,972] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,972] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:21:41,972] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,972] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,975] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,975] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,975] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,975] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:21:41,976] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,976] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,978] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,979] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:41,979] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,979] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:21:41,979] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,979] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,982] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:41,982] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:41,982] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:41,982] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:21:41,982] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:41,983] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:41,989] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,989] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,990] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,991] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,992] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 3 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,993] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,994] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,995] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,995] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,995] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,996] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,997] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,998] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,998] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,998] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,999] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,999] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:41,999] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,000] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,001] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,002] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,003] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output_final-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,004] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,005] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:21:42,007] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:42,007] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:21:42,008] INFO Created log for partition output_final-0 in /tmp/kafka-logs-0/output_final-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:42,009] INFO [Partition output_final-0 broker=0] No checkpointed highwatermark is found for partition output_final-0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,009] INFO [Partition output_final-0 broker=0] Log loaded for partition output_final-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,009] INFO [Partition output_final-0 broker=0] output_final-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:42,013] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:42,016] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:42,017] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:42,017] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:42,018] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,018] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,018] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:42,057] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-97d2b67a-dbd8-4bb5-9c46-1e7e10449ac2-StreamThread-2-evaluation.consumer-20e5bf2d-7c42-4622-b297-266d49d30bb8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,061] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,072] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:42,081] INFO [GroupCoordinator 0]: Preparing to rebalance group 71b53bb8-0ba7-42bb-b822-146b1698d448 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member your_client_idbdd465f9-9917-437e-bb5b-9a5cc1d4e811-fb9f601d-354d-455c-9399-77cd6ea48902 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,081] INFO [GroupCoordinator 0]: Stabilized group 71b53bb8-0ba7-42bb-b822-146b1698d448 generation 1 (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,084] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:42,084] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:42,085] INFO [GroupCoordinator 0]: Assignment received from leader for group 71b53bb8-0ba7-42bb-b822-146b1698d448 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,087] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:42,088] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:42,089] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:42,090] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,090] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,090] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_c12854b0-a2de-4759-b8e3-a28c64ddbd0a-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:42,091] INFO Creating topic prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:21:42,095] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:42,099] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:42,099] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:21:42,100] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:42,102] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,102] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,102] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_672d338c-73a6-4a3a-80d5-d827e3b50a7b-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:42,108] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:42,110] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: Adding new member prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-97d2b67a-dbd8-4bb5-9c46-1e7e10449ac2-StreamThread-1-evaluation.consumer-332cc26f-ecea-41e2-b20a-2e4fede91455 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,111] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:21:42,112] INFO [Log partition=prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:21:42,112] INFO Created log for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:21:42,113] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,113] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] Log loaded for partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:21:42,113] INFO [Partition prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 broker=0] prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba-_Store_e0ba49eb-ee2f-480e-a444-937d1030d344-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:21:42,127] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba generation 2 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:42,130] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_d5afdaf3-eb99-4ce0-835f-178c48b1a8ba for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:52,839] INFO Terminating process due to signal SIGINT (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:21:52,840] INFO Shutting down SupportedServerStartable (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:52,840] INFO Shutting down KafkaServer (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:21:52,840] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2020-03-26 17:21:52,841] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2020-03-26 17:21:52,856] INFO [KafkaServer id=0] Controlled shutdown succeeded (kafka.server.KafkaServer)
[2020-03-26 17:21:52,858] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:52,859] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:52,859] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:21:52,859] INFO [SocketServer brokerId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:21:52,864] INFO [SocketServer brokerId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2020-03-26 17:21:52,864] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:21:52,865] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2020-03-26 17:21:52,867] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:52,906] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:52,906] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:52,906] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2020-03-26 17:21:52,907] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,034] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,034] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,036] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:53,036] INFO [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:21:53,037] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2020-03-26 17:21:53,037] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:53,038] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:53,038] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:21:53,038] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:21:53,039] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:53,039] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,087] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,087] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,088] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,222] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,222] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,223] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:21:53,224] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2020-03-26 17:21:53,224] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:53,224] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:53,224] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:21:53,225] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:53,226] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:21:53,226] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:21:53,226] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2020-03-26 17:21:53,226] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,335] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,335] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,335] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,386] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,386] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,386] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,588] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,588] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,589] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,793] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,793] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:21:53,796] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2020-03-26 17:21:53,797] INFO Shutting down. (kafka.log.LogManager)
[2020-03-26 17:21:53,811] INFO [ProducerStateManager partition=__consumer_offsets-21] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-03-26 17:21:53,821] INFO [ProducerStateManager partition=__consumer_offsets-48] Writing producer snapshot at offset 1 (kafka.log.ProducerStateManager)
[2020-03-26 17:21:53,841] INFO Shutdown complete. (kafka.log.LogManager)
[2020-03-26 17:21:53,846] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:53,953] INFO Session: 0x1003f3274ea0000 closed (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:21:53,953] INFO EventThread shut down for session: 0x1003f3274ea0000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:21:53,954] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:21:53,954] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:54,662] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:54,662] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:54,662] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:55,663] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:55,663] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:55,664] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:56,668] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:56,668] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:21:56,669] INFO [SocketServer brokerId=0] Shutting down socket server (kafka.network.SocketServer)
[2020-03-26 17:21:56,685] INFO [SocketServer brokerId=0] Shutdown completed (kafka.network.SocketServer)
[2020-03-26 17:21:56,687] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2020-03-26 17:21:59,588] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,590] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,593] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,593] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,594] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:59,594] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:59,594] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2020-03-26 17:21:59,594] WARN Either no config or no quorum defined in config, running  in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2020-03-26 17:21:59,595] INFO Log4j found with jmx enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2020-03-26 17:21:59,605] INFO Reading configuration from: etc/kafka/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,605] WARN etc/kafka/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,605] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,605] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-03-26 17:21:59,606] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2020-03-26 17:21:59,608] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:59,619] INFO Server environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,619] INFO Server environment:host.name=192.168.8.101 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,619] INFO Server environment:java.version=1.8.0_131 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,619] INFO Server environment:java.vendor=Oracle Corporation (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,619] INFO Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,619] INFO Server environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:os.name=Mac OS X (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:os.arch=x86_64 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:os.version=10.15.3 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:user.name=riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:user.home=/Users/riccardo (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,620] INFO Server environment:os.memory.free=496MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,621] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,621] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,622] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,622] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,623] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2020-03-26 17:21:59,636] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2020-03-26 17:21:59,638] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:59,647] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2020-03-26 17:21:59,660] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2020-03-26 17:21:59,663] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:59,666] INFO Snapshotting: 0x0 to /tmp/zookeeper/version-2/snapshot.0 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2020-03-26 17:21:59,679] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-03-26 17:22:01,545] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2020-03-26 17:22:01,892] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:22:01,942] WARN The package io.confluent.support.metrics.collectors.FullCollector for collecting the full set of support metrics could not be loaded, so we are reverting to anonymous, basic metric collection. If you are a Confluent customer, please refer to the Confluent Platform documentation, section Proactive Support, on how to activate full metrics collection. (io.confluent.support.metrics.KafkaSupportConfig)
[2020-03-26 17:22:01,942] WARN The support metrics collection feature ("Metrics") of Proactive Support is disabled. (io.confluent.support.metrics.SupportedServerStartable)
[2020-03-26 17:22:01,943] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2020-03-26 17:22:01,944] INFO starting (kafka.server.KafkaServer)
[2020-03-26 17:22:01,945] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2020-03-26 17:22:01,959] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:22:01,967] INFO Client environment:zookeeper.version=3.5.7-f0fdd52973d373ffd9c86b81d99842dc2c7f660e, built on 02/10/2020 11:30 GMT (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,967] INFO Client environment:host.name=192.168.8.101 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,967] INFO Client environment:java.version=1.8.0_131 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,967] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,967] INFO Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_131.jdk/Contents/Home/jre (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,967] INFO Client environment:java.class.path=/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zstd-jni-1.4.3-1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-io-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-logging-1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-common-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/reflections-0.9.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-basic-auth-extension-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jopt-simple-5.0.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-client-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-codec-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-locator-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-javadoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-java8-compat_2.12-0.9.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/aopalliance-repackaged-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlets-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-paranamer-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpcore-4.4.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/guava-20.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/argparse4j-0.7.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/activation-1.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-json-provider-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-util-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-server-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpmime-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/rocksdbjni-5.18.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-file-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-collection-compat_2.12-2.1.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.servlet-api-3.1.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-dataformat-csv-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/log4j-1.2.17.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-reflect-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-hk2-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-continuation-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/maven-artifact-3.6.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-core-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/plexus-utils-3.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-jaxrs-base-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-core-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.ws.rs-api-2.1.5.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-cli-1.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-logging_2.12-3.9.2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javassist-3.22.0-CR2.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/paranamer-2.8.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-json-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-container-servlet-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jaxb-api-2.3.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/snappy-java-1.1.7.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/avro-1.9.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-http-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/metrics-core-2.2.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/scala-library-2.12.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-jaxb-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-jute-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/osgi-resource-locator-1.0.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-mirror-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-client-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-codec-1.11.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/validation-api-2.0.1.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-scaladoc.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-clients-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-server-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/audience-annotations-0.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/javax.ws.rs-api-2.1.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-api-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-transforms-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-resolver-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-security-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-annotations-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-module-scala_2.12-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/httpclient-4.5.9.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/connect-runtime-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.annotation-api-1.3.4.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-compress-1.19.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-handler-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-unix-common-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-transport-native-epoll-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-log4j-appender-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-media-jaxb-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-scala_2.12-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka_2.12-5.4.1-ccs-test-sources.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-api-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jetty-servlet-9.4.20.v20190813.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/lz4-java-1.6.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/support-metrics-client-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-tools-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-examples-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-databind-2.9.10.3.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jakarta.inject-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-utils-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jersey-common-2.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/jackson-datatype-jdk8-2.9.10.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/netty-buffer-4.1.45.Final.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/kafka-streams-test-utils-5.4.1-ccs.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/slf4j-log4j12-1.7.28.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/zookeeper-3.5.7.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/hk2-api-2.5.0.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../share/java/kafka/commons-lang3-3.8.1.jar:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/dependant-libs-2.12.10/*:/Users/riccardo/Documents/_Teaching/kafka-training/confluent/bin/../support-metrics-client/build/libs/*:/usr/share/java/support-metrics-client/* (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:java.library.path=/Users/riccardo/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:. (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:java.io.tmpdir=/var/folders/q8/d19_s4jd63x_4wvqhw5j_1v00000gn/T/ (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:os.name=Mac OS X (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:os.arch=x86_64 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:os.version=10.15.3 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:user.name=riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:user.home=/Users/riccardo (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:user.dir=/Users/riccardo/Documents/_Teaching/kafka-training/confluent (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:os.memory.free=980MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,968] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,969] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,971] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@2145b572 (org.apache.zookeeper.ZooKeeper)
[2020-03-26 17:22:01,975] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2020-03-26 17:22:01,980] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2020-03-26 17:22:01,985] INFO zookeeper.request.timeout value is 0. feature enabled= (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:22:01,986] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:22:01,989] INFO Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:22:02,000] INFO Socket connection established, initiating session, client: /127.0.0.1:52283, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:22:02,008] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2020-03-26 17:22:02,021] INFO Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x1003f32c9000000, negotiated timeout = 6000 (org.apache.zookeeper.ClientCnxn)
[2020-03-26 17:22:02,023] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2020-03-26 17:22:02,236] INFO Cluster ID = OmdbKCx9QmWGE4Ba-IPm9Q (kafka.server.KafkaServer)
[2020-03-26 17:22:02,245] WARN No meta.properties file under dir /tmp/kafka-logs-0/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2020-03-26 17:22:02,291] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:22:02,298] INFO KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.4-IV1
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-0
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.4-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2020-03-26 17:22:02,317] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:22:02,317] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:22:02,317] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2020-03-26 17:22:02,335] INFO Log directory /tmp/kafka-logs-0 not found, creating it. (kafka.log.LogManager)
[2020-03-26 17:22:02,341] INFO Loading logs. (kafka.log.LogManager)
[2020-03-26 17:22:02,348] INFO Logs loading complete in 7 ms. (kafka.log.LogManager)
[2020-03-26 17:22:02,359] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2020-03-26 17:22:02,362] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2020-03-26 17:22:02,653] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2020-03-26 17:22:02,679] INFO [SocketServer brokerId=0] Created data-plane acceptor and processors for endpoint : EndPoint(null,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.network.SocketServer)
[2020-03-26 17:22:02,680] INFO [SocketServer brokerId=0] Started 1 acceptor threads for data-plane (kafka.network.SocketServer)
[2020-03-26 17:22:02,694] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,694] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,695] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,695] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,703] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2020-03-26 17:22:02,720] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2020-03-26 17:22:02,734] INFO Stat of the created znode at /brokers/ids/0 is: 24,24,1585236122729,1585236122729,1,0,0,72127081391063040,196,0,24
 (kafka.zk.KafkaZkClient)
[2020-03-26 17:22:02,735] INFO Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(192.168.8.101,9092,ListenerName(PLAINTEXT),PLAINTEXT)), czxid (broker epoch): 24 (kafka.zk.KafkaZkClient)
[2020-03-26 17:22:02,778] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,779] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,780] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,784] INFO Successfully created /controller_epoch with initial epoch 0 (kafka.zk.KafkaZkClient)
[2020-03-26 17:22:02,804] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:02,805] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:02,809] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:02,814] INFO [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1 (kafka.coordinator.transaction.ProducerIdManager)
[2020-03-26 17:22:02,831] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:22:02,833] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2020-03-26 17:22:02,833] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2020-03-26 17:22:02,854] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2020-03-26 17:22:02,867] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2020-03-26 17:22:02,875] INFO [SocketServer brokerId=0] Started data-plane processors for 1 acceptors (kafka.network.SocketServer)
[2020-03-26 17:22:02,877] INFO Kafka version: 5.4.1-ccs (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:22:02,877] INFO Kafka commitId: 1c8f62230319e789 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:22:02,877] INFO Kafka startTimeMs: 1585236122875 (org.apache.kafka.common.utils.AppInfoParser)
[2020-03-26 17:22:02,878] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2020-03-26 17:22:20,594] INFO Creating topic W1 with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:22:20,603] INFO [KafkaApi-0] Auto creation of topic W1 with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:22:20,668] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:22:20,728] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:20,733] INFO [Log partition=W1-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 32 ms (kafka.log.Log)
[2020-03-26 17:22:20,735] INFO Created log for partition W1-0 in /tmp/kafka-logs-0/W1-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:20,735] INFO [Partition W1-0 broker=0] No checkpointed highwatermark is found for partition W1-0 (kafka.cluster.Partition)
[2020-03-26 17:22:20,736] INFO [Partition W1-0 broker=0] Log loaded for partition W1-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:20,736] INFO [Partition W1-0 broker=0] W1-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,187] INFO Creating topic __consumer_offsets with configuration {segment.bytes=104857600, compression.type=producer, cleanup.policy=compact} and initial partition assignment Map(23 -> ArrayBuffer(0), 32 -> ArrayBuffer(0), 41 -> ArrayBuffer(0), 17 -> ArrayBuffer(0), 8 -> ArrayBuffer(0), 35 -> ArrayBuffer(0), 44 -> ArrayBuffer(0), 26 -> ArrayBuffer(0), 11 -> ArrayBuffer(0), 29 -> ArrayBuffer(0), 38 -> ArrayBuffer(0), 47 -> ArrayBuffer(0), 20 -> ArrayBuffer(0), 2 -> ArrayBuffer(0), 5 -> ArrayBuffer(0), 14 -> ArrayBuffer(0), 46 -> ArrayBuffer(0), 49 -> ArrayBuffer(0), 40 -> ArrayBuffer(0), 13 -> ArrayBuffer(0), 4 -> ArrayBuffer(0), 22 -> ArrayBuffer(0), 31 -> ArrayBuffer(0), 16 -> ArrayBuffer(0), 7 -> ArrayBuffer(0), 43 -> ArrayBuffer(0), 25 -> ArrayBuffer(0), 34 -> ArrayBuffer(0), 10 -> ArrayBuffer(0), 37 -> ArrayBuffer(0), 1 -> ArrayBuffer(0), 19 -> ArrayBuffer(0), 28 -> ArrayBuffer(0), 45 -> ArrayBuffer(0), 27 -> ArrayBuffer(0), 36 -> ArrayBuffer(0), 18 -> ArrayBuffer(0), 9 -> ArrayBuffer(0), 21 -> ArrayBuffer(0), 48 -> ArrayBuffer(0), 3 -> ArrayBuffer(0), 12 -> ArrayBuffer(0), 30 -> ArrayBuffer(0), 39 -> ArrayBuffer(0), 15 -> ArrayBuffer(0), 42 -> ArrayBuffer(0), 24 -> ArrayBuffer(0), 6 -> ArrayBuffer(0), 33 -> ArrayBuffer(0), 0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:22:50,196] INFO [KafkaApi-0] Auto creation of topic __consumer_offsets with 50 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:22:50,279] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(__consumer_offsets-22, __consumer_offsets-30, __consumer_offsets-8, __consumer_offsets-21, __consumer_offsets-4, __consumer_offsets-27, __consumer_offsets-7, __consumer_offsets-9, __consumer_offsets-46, __consumer_offsets-25, __consumer_offsets-35, __consumer_offsets-41, __consumer_offsets-33, __consumer_offsets-23, __consumer_offsets-49, __consumer_offsets-47, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-31, __consumer_offsets-36, __consumer_offsets-42, __consumer_offsets-3, __consumer_offsets-18, __consumer_offsets-37, __consumer_offsets-15, __consumer_offsets-24, __consumer_offsets-38, __consumer_offsets-17, __consumer_offsets-48, __consumer_offsets-19, __consumer_offsets-11, __consumer_offsets-13, __consumer_offsets-2, __consumer_offsets-43, __consumer_offsets-6, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-0, __consumer_offsets-44, __consumer_offsets-39, __consumer_offsets-12, __consumer_offsets-45, __consumer_offsets-1, __consumer_offsets-5, __consumer_offsets-26, __consumer_offsets-29, __consumer_offsets-34, __consumer_offsets-10, __consumer_offsets-32, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:22:50,284] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,284] INFO [Log partition=__consumer_offsets-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:22:50,285] INFO Created log for partition __consumer_offsets-0 in /tmp/kafka-logs-0/__consumer_offsets-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,286] INFO [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,286] INFO [Partition __consumer_offsets-0 broker=0] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,286] INFO [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,290] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,291] INFO [Log partition=__consumer_offsets-29, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,292] INFO Created log for partition __consumer_offsets-29 in /tmp/kafka-logs-0/__consumer_offsets-29 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,292] INFO [Partition __consumer_offsets-29 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-29 (kafka.cluster.Partition)
[2020-03-26 17:22:50,292] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,292] INFO [Partition __consumer_offsets-29 broker=0] __consumer_offsets-29 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,296] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,297] INFO [Log partition=__consumer_offsets-48, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:22:50,297] INFO Created log for partition __consumer_offsets-48 in /tmp/kafka-logs-0/__consumer_offsets-48 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,297] INFO [Partition __consumer_offsets-48 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-48 (kafka.cluster.Partition)
[2020-03-26 17:22:50,297] INFO [Partition __consumer_offsets-48 broker=0] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,297] INFO [Partition __consumer_offsets-48 broker=0] __consumer_offsets-48 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,300] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,301] INFO [Log partition=__consumer_offsets-10, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,301] INFO Created log for partition __consumer_offsets-10 in /tmp/kafka-logs-0/__consumer_offsets-10 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,301] INFO [Partition __consumer_offsets-10 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-10 (kafka.cluster.Partition)
[2020-03-26 17:22:50,301] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,301] INFO [Partition __consumer_offsets-10 broker=0] __consumer_offsets-10 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,304] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,304] INFO [Log partition=__consumer_offsets-45, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,305] INFO Created log for partition __consumer_offsets-45 in /tmp/kafka-logs-0/__consumer_offsets-45 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,305] INFO [Partition __consumer_offsets-45 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-45 (kafka.cluster.Partition)
[2020-03-26 17:22:50,305] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,305] INFO [Partition __consumer_offsets-45 broker=0] __consumer_offsets-45 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,307] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,308] INFO [Log partition=__consumer_offsets-26, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,308] INFO Created log for partition __consumer_offsets-26 in /tmp/kafka-logs-0/__consumer_offsets-26 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,308] INFO [Partition __consumer_offsets-26 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-26 (kafka.cluster.Partition)
[2020-03-26 17:22:50,308] INFO [Partition __consumer_offsets-26 broker=0] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,308] INFO [Partition __consumer_offsets-26 broker=0] __consumer_offsets-26 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,312] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,312] INFO [Log partition=__consumer_offsets-7, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,313] INFO Created log for partition __consumer_offsets-7 in /tmp/kafka-logs-0/__consumer_offsets-7 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,313] INFO [Partition __consumer_offsets-7 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-7 (kafka.cluster.Partition)
[2020-03-26 17:22:50,313] INFO [Partition __consumer_offsets-7 broker=0] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,313] INFO [Partition __consumer_offsets-7 broker=0] __consumer_offsets-7 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,316] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,316] INFO [Log partition=__consumer_offsets-42, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,316] INFO Created log for partition __consumer_offsets-42 in /tmp/kafka-logs-0/__consumer_offsets-42 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,316] INFO [Partition __consumer_offsets-42 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-42 (kafka.cluster.Partition)
[2020-03-26 17:22:50,317] INFO [Partition __consumer_offsets-42 broker=0] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,317] INFO [Partition __consumer_offsets-42 broker=0] __consumer_offsets-42 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,320] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,320] INFO [Log partition=__consumer_offsets-4, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,320] INFO Created log for partition __consumer_offsets-4 in /tmp/kafka-logs-0/__consumer_offsets-4 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,320] INFO [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4 (kafka.cluster.Partition)
[2020-03-26 17:22:50,320] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,320] INFO [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,323] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,324] INFO [Log partition=__consumer_offsets-23, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,324] INFO Created log for partition __consumer_offsets-23 in /tmp/kafka-logs-0/__consumer_offsets-23 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,324] INFO [Partition __consumer_offsets-23 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-23 (kafka.cluster.Partition)
[2020-03-26 17:22:50,324] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,324] INFO [Partition __consumer_offsets-23 broker=0] __consumer_offsets-23 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,327] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,328] INFO [Log partition=__consumer_offsets-1, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,328] INFO Created log for partition __consumer_offsets-1 in /tmp/kafka-logs-0/__consumer_offsets-1 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,328] INFO [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1 (kafka.cluster.Partition)
[2020-03-26 17:22:50,328] INFO [Partition __consumer_offsets-1 broker=0] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,328] INFO [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,331] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,332] INFO [Log partition=__consumer_offsets-20, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,332] INFO Created log for partition __consumer_offsets-20 in /tmp/kafka-logs-0/__consumer_offsets-20 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,332] INFO [Partition __consumer_offsets-20 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-20 (kafka.cluster.Partition)
[2020-03-26 17:22:50,332] INFO [Partition __consumer_offsets-20 broker=0] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,332] INFO [Partition __consumer_offsets-20 broker=0] __consumer_offsets-20 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,336] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,336] INFO [Log partition=__consumer_offsets-39, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,337] INFO Created log for partition __consumer_offsets-39 in /tmp/kafka-logs-0/__consumer_offsets-39 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,337] INFO [Partition __consumer_offsets-39 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-39 (kafka.cluster.Partition)
[2020-03-26 17:22:50,337] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,337] INFO [Partition __consumer_offsets-39 broker=0] __consumer_offsets-39 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,340] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,340] INFO [Log partition=__consumer_offsets-17, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,341] INFO Created log for partition __consumer_offsets-17 in /tmp/kafka-logs-0/__consumer_offsets-17 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,341] INFO [Partition __consumer_offsets-17 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-17 (kafka.cluster.Partition)
[2020-03-26 17:22:50,341] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,341] INFO [Partition __consumer_offsets-17 broker=0] __consumer_offsets-17 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,343] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,344] INFO [Log partition=__consumer_offsets-36, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,344] INFO Created log for partition __consumer_offsets-36 in /tmp/kafka-logs-0/__consumer_offsets-36 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,344] INFO [Partition __consumer_offsets-36 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-36 (kafka.cluster.Partition)
[2020-03-26 17:22:50,344] INFO [Partition __consumer_offsets-36 broker=0] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,344] INFO [Partition __consumer_offsets-36 broker=0] __consumer_offsets-36 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,347] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,348] INFO [Log partition=__consumer_offsets-14, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,348] INFO Created log for partition __consumer_offsets-14 in /tmp/kafka-logs-0/__consumer_offsets-14 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,348] INFO [Partition __consumer_offsets-14 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-14 (kafka.cluster.Partition)
[2020-03-26 17:22:50,348] INFO [Partition __consumer_offsets-14 broker=0] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,348] INFO [Partition __consumer_offsets-14 broker=0] __consumer_offsets-14 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,351] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,351] INFO [Log partition=__consumer_offsets-33, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,352] INFO Created log for partition __consumer_offsets-33 in /tmp/kafka-logs-0/__consumer_offsets-33 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,352] INFO [Partition __consumer_offsets-33 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-33 (kafka.cluster.Partition)
[2020-03-26 17:22:50,352] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,352] INFO [Partition __consumer_offsets-33 broker=0] __consumer_offsets-33 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,355] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,355] INFO [Log partition=__consumer_offsets-49, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,355] INFO Created log for partition __consumer_offsets-49 in /tmp/kafka-logs-0/__consumer_offsets-49 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,355] INFO [Partition __consumer_offsets-49 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-49 (kafka.cluster.Partition)
[2020-03-26 17:22:50,355] INFO [Partition __consumer_offsets-49 broker=0] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,355] INFO [Partition __consumer_offsets-49 broker=0] __consumer_offsets-49 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,358] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,358] INFO [Log partition=__consumer_offsets-11, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,359] INFO Created log for partition __consumer_offsets-11 in /tmp/kafka-logs-0/__consumer_offsets-11 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,359] INFO [Partition __consumer_offsets-11 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-11 (kafka.cluster.Partition)
[2020-03-26 17:22:50,359] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,359] INFO [Partition __consumer_offsets-11 broker=0] __consumer_offsets-11 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,362] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,363] INFO [Log partition=__consumer_offsets-30, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,363] INFO Created log for partition __consumer_offsets-30 in /tmp/kafka-logs-0/__consumer_offsets-30 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,363] INFO [Partition __consumer_offsets-30 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-30 (kafka.cluster.Partition)
[2020-03-26 17:22:50,363] INFO [Partition __consumer_offsets-30 broker=0] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,363] INFO [Partition __consumer_offsets-30 broker=0] __consumer_offsets-30 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,367] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,367] INFO [Log partition=__consumer_offsets-46, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,367] INFO Created log for partition __consumer_offsets-46 in /tmp/kafka-logs-0/__consumer_offsets-46 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,367] INFO [Partition __consumer_offsets-46 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-46 (kafka.cluster.Partition)
[2020-03-26 17:22:50,367] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,368] INFO [Partition __consumer_offsets-46 broker=0] __consumer_offsets-46 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,370] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,371] INFO [Log partition=__consumer_offsets-27, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,371] INFO Created log for partition __consumer_offsets-27 in /tmp/kafka-logs-0/__consumer_offsets-27 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,371] INFO [Partition __consumer_offsets-27 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-27 (kafka.cluster.Partition)
[2020-03-26 17:22:50,371] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,371] INFO [Partition __consumer_offsets-27 broker=0] __consumer_offsets-27 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,374] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,375] INFO [Log partition=__consumer_offsets-8, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,375] INFO Created log for partition __consumer_offsets-8 in /tmp/kafka-logs-0/__consumer_offsets-8 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,375] INFO [Partition __consumer_offsets-8 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-8 (kafka.cluster.Partition)
[2020-03-26 17:22:50,375] INFO [Partition __consumer_offsets-8 broker=0] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,375] INFO [Partition __consumer_offsets-8 broker=0] __consumer_offsets-8 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,379] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,379] INFO [Log partition=__consumer_offsets-24, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,379] INFO Created log for partition __consumer_offsets-24 in /tmp/kafka-logs-0/__consumer_offsets-24 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,380] INFO [Partition __consumer_offsets-24 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-24 (kafka.cluster.Partition)
[2020-03-26 17:22:50,380] INFO [Partition __consumer_offsets-24 broker=0] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,380] INFO [Partition __consumer_offsets-24 broker=0] __consumer_offsets-24 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,382] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,383] INFO [Log partition=__consumer_offsets-43, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,383] INFO Created log for partition __consumer_offsets-43 in /tmp/kafka-logs-0/__consumer_offsets-43 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,383] INFO [Partition __consumer_offsets-43 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-43 (kafka.cluster.Partition)
[2020-03-26 17:22:50,383] INFO [Partition __consumer_offsets-43 broker=0] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,383] INFO [Partition __consumer_offsets-43 broker=0] __consumer_offsets-43 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,386] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,387] INFO [Log partition=__consumer_offsets-5, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,387] INFO Created log for partition __consumer_offsets-5 in /tmp/kafka-logs-0/__consumer_offsets-5 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,387] INFO [Partition __consumer_offsets-5 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-5 (kafka.cluster.Partition)
[2020-03-26 17:22:50,387] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,387] INFO [Partition __consumer_offsets-5 broker=0] __consumer_offsets-5 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,390] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,390] INFO [Log partition=__consumer_offsets-21, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,391] INFO Created log for partition __consumer_offsets-21 in /tmp/kafka-logs-0/__consumer_offsets-21 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,391] INFO [Partition __consumer_offsets-21 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-21 (kafka.cluster.Partition)
[2020-03-26 17:22:50,391] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,391] INFO [Partition __consumer_offsets-21 broker=0] __consumer_offsets-21 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,394] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,394] INFO [Log partition=__consumer_offsets-40, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,395] INFO Created log for partition __consumer_offsets-40 in /tmp/kafka-logs-0/__consumer_offsets-40 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,395] INFO [Partition __consumer_offsets-40 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-40 (kafka.cluster.Partition)
[2020-03-26 17:22:50,395] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,395] INFO [Partition __consumer_offsets-40 broker=0] __consumer_offsets-40 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,398] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,399] INFO [Log partition=__consumer_offsets-2, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,399] INFO Created log for partition __consumer_offsets-2 in /tmp/kafka-logs-0/__consumer_offsets-2 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,399] INFO [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2 (kafka.cluster.Partition)
[2020-03-26 17:22:50,399] INFO [Partition __consumer_offsets-2 broker=0] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,399] INFO [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,402] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,403] INFO [Log partition=__consumer_offsets-37, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,403] INFO Created log for partition __consumer_offsets-37 in /tmp/kafka-logs-0/__consumer_offsets-37 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,403] INFO [Partition __consumer_offsets-37 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-37 (kafka.cluster.Partition)
[2020-03-26 17:22:50,403] INFO [Partition __consumer_offsets-37 broker=0] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,403] INFO [Partition __consumer_offsets-37 broker=0] __consumer_offsets-37 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,406] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,407] INFO [Log partition=__consumer_offsets-18, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,407] INFO Created log for partition __consumer_offsets-18 in /tmp/kafka-logs-0/__consumer_offsets-18 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,407] INFO [Partition __consumer_offsets-18 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-18 (kafka.cluster.Partition)
[2020-03-26 17:22:50,407] INFO [Partition __consumer_offsets-18 broker=0] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,407] INFO [Partition __consumer_offsets-18 broker=0] __consumer_offsets-18 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,410] INFO [Log partition=__consumer_offsets-34, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,411] INFO Created log for partition __consumer_offsets-34 in /tmp/kafka-logs-0/__consumer_offsets-34 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,411] INFO [Partition __consumer_offsets-34 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-34 (kafka.cluster.Partition)
[2020-03-26 17:22:50,411] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,411] INFO [Partition __consumer_offsets-34 broker=0] __consumer_offsets-34 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,414] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,414] INFO [Log partition=__consumer_offsets-15, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,414] INFO Created log for partition __consumer_offsets-15 in /tmp/kafka-logs-0/__consumer_offsets-15 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,414] INFO [Partition __consumer_offsets-15 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-15 (kafka.cluster.Partition)
[2020-03-26 17:22:50,414] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,414] INFO [Partition __consumer_offsets-15 broker=0] __consumer_offsets-15 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,417] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,417] INFO [Log partition=__consumer_offsets-12, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,418] INFO Created log for partition __consumer_offsets-12 in /tmp/kafka-logs-0/__consumer_offsets-12 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,418] INFO [Partition __consumer_offsets-12 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-12 (kafka.cluster.Partition)
[2020-03-26 17:22:50,418] INFO [Partition __consumer_offsets-12 broker=0] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,418] INFO [Partition __consumer_offsets-12 broker=0] __consumer_offsets-12 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,420] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,421] INFO [Log partition=__consumer_offsets-31, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,421] INFO Created log for partition __consumer_offsets-31 in /tmp/kafka-logs-0/__consumer_offsets-31 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,421] INFO [Partition __consumer_offsets-31 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-31 (kafka.cluster.Partition)
[2020-03-26 17:22:50,421] INFO [Partition __consumer_offsets-31 broker=0] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,421] INFO [Partition __consumer_offsets-31 broker=0] __consumer_offsets-31 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,424] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,424] INFO [Log partition=__consumer_offsets-9, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,425] INFO Created log for partition __consumer_offsets-9 in /tmp/kafka-logs-0/__consumer_offsets-9 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,425] INFO [Partition __consumer_offsets-9 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-9 (kafka.cluster.Partition)
[2020-03-26 17:22:50,425] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,425] INFO [Partition __consumer_offsets-9 broker=0] __consumer_offsets-9 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,428] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,428] INFO [Log partition=__consumer_offsets-47, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,429] INFO Created log for partition __consumer_offsets-47 in /tmp/kafka-logs-0/__consumer_offsets-47 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,429] INFO [Partition __consumer_offsets-47 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-47 (kafka.cluster.Partition)
[2020-03-26 17:22:50,429] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,429] INFO [Partition __consumer_offsets-47 broker=0] __consumer_offsets-47 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,432] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,432] INFO [Log partition=__consumer_offsets-19, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,433] INFO Created log for partition __consumer_offsets-19 in /tmp/kafka-logs-0/__consumer_offsets-19 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,433] INFO [Partition __consumer_offsets-19 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-19 (kafka.cluster.Partition)
[2020-03-26 17:22:50,433] INFO [Partition __consumer_offsets-19 broker=0] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,433] INFO [Partition __consumer_offsets-19 broker=0] __consumer_offsets-19 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,436] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,436] INFO [Log partition=__consumer_offsets-28, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,437] INFO Created log for partition __consumer_offsets-28 in /tmp/kafka-logs-0/__consumer_offsets-28 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,437] INFO [Partition __consumer_offsets-28 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-28 (kafka.cluster.Partition)
[2020-03-26 17:22:50,437] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,437] INFO [Partition __consumer_offsets-28 broker=0] __consumer_offsets-28 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,440] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,440] INFO [Log partition=__consumer_offsets-38, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,440] INFO Created log for partition __consumer_offsets-38 in /tmp/kafka-logs-0/__consumer_offsets-38 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,440] INFO [Partition __consumer_offsets-38 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-38 (kafka.cluster.Partition)
[2020-03-26 17:22:50,440] INFO [Partition __consumer_offsets-38 broker=0] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,440] INFO [Partition __consumer_offsets-38 broker=0] __consumer_offsets-38 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,443] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,444] INFO [Log partition=__consumer_offsets-35, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,444] INFO Created log for partition __consumer_offsets-35 in /tmp/kafka-logs-0/__consumer_offsets-35 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,444] INFO [Partition __consumer_offsets-35 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-35 (kafka.cluster.Partition)
[2020-03-26 17:22:50,444] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,444] INFO [Partition __consumer_offsets-35 broker=0] __consumer_offsets-35 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,447] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,447] INFO [Log partition=__consumer_offsets-6, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,448] INFO Created log for partition __consumer_offsets-6 in /tmp/kafka-logs-0/__consumer_offsets-6 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,448] INFO [Partition __consumer_offsets-6 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-6 (kafka.cluster.Partition)
[2020-03-26 17:22:50,448] INFO [Partition __consumer_offsets-6 broker=0] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,448] INFO [Partition __consumer_offsets-6 broker=0] __consumer_offsets-6 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,451] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,451] INFO [Log partition=__consumer_offsets-44, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,452] INFO Created log for partition __consumer_offsets-44 in /tmp/kafka-logs-0/__consumer_offsets-44 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,452] INFO [Partition __consumer_offsets-44 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-44 (kafka.cluster.Partition)
[2020-03-26 17:22:50,452] INFO [Partition __consumer_offsets-44 broker=0] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,452] INFO [Partition __consumer_offsets-44 broker=0] __consumer_offsets-44 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,454] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,455] INFO [Log partition=__consumer_offsets-25, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,455] INFO Created log for partition __consumer_offsets-25 in /tmp/kafka-logs-0/__consumer_offsets-25 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,455] INFO [Partition __consumer_offsets-25 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-25 (kafka.cluster.Partition)
[2020-03-26 17:22:50,455] INFO [Partition __consumer_offsets-25 broker=0] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,455] INFO [Partition __consumer_offsets-25 broker=0] __consumer_offsets-25 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,458] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,458] INFO [Log partition=__consumer_offsets-16, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,459] INFO Created log for partition __consumer_offsets-16 in /tmp/kafka-logs-0/__consumer_offsets-16 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,459] INFO [Partition __consumer_offsets-16 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-16 (kafka.cluster.Partition)
[2020-03-26 17:22:50,459] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,459] INFO [Partition __consumer_offsets-16 broker=0] __consumer_offsets-16 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,462] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,462] INFO [Log partition=__consumer_offsets-22, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,462] INFO Created log for partition __consumer_offsets-22 in /tmp/kafka-logs-0/__consumer_offsets-22 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,463] INFO [Partition __consumer_offsets-22 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-22 (kafka.cluster.Partition)
[2020-03-26 17:22:50,463] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,463] INFO [Partition __consumer_offsets-22 broker=0] __consumer_offsets-22 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,465] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,466] INFO [Log partition=__consumer_offsets-41, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,466] INFO Created log for partition __consumer_offsets-41 in /tmp/kafka-logs-0/__consumer_offsets-41 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,466] INFO [Partition __consumer_offsets-41 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-41 (kafka.cluster.Partition)
[2020-03-26 17:22:50,466] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,466] INFO [Partition __consumer_offsets-41 broker=0] __consumer_offsets-41 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,469] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,469] INFO [Log partition=__consumer_offsets-32, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,469] INFO Created log for partition __consumer_offsets-32 in /tmp/kafka-logs-0/__consumer_offsets-32 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,469] INFO [Partition __consumer_offsets-32 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-32 (kafka.cluster.Partition)
[2020-03-26 17:22:50,469] INFO [Partition __consumer_offsets-32 broker=0] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,469] INFO [Partition __consumer_offsets-32 broker=0] __consumer_offsets-32 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,472] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,472] INFO [Log partition=__consumer_offsets-3, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:22:50,473] INFO Created log for partition __consumer_offsets-3 in /tmp/kafka-logs-0/__consumer_offsets-3 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,473] INFO [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3 (kafka.cluster.Partition)
[2020-03-26 17:22:50,473] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,473] INFO [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,475] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:22:50,476] INFO [Log partition=__consumer_offsets-13, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:22:50,476] INFO Created log for partition __consumer_offsets-13 in /tmp/kafka-logs-0/__consumer_offsets-13 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 104857600, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:22:50,476] INFO [Partition __consumer_offsets-13 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-13 (kafka.cluster.Partition)
[2020-03-26 17:22:50,476] INFO [Partition __consumer_offsets-13 broker=0] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:22:50,476] INFO [Partition __consumer_offsets-13 broker=0] __consumer_offsets-13 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:22:50,478] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,479] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,481] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 2 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,482] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-25 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,482] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,482] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-31 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,482] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,482] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-37 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-43 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-49 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,483] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-44 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-7 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,484] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-13 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-19 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-8 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-14 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,485] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-20 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-26 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-32 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-38 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-6 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,486] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-12 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-18 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-24 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-30 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-36 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,487] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,488] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,488] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,488] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-48 in 0 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:22:50,520] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-875 in state PreparingRebalance with old generation 0 (__consumer_offsets-31) (reason: Adding new member consumer-console-consumer-875-1-751bf938-9e11-45ca-8818-1fc0c161c5ad with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:50,525] INFO [GroupCoordinator 0]: Stabilized group console-consumer-875 generation 1 (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:50,540] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-875 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:50,628] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-875-1-751bf938-9e11-45ca-8818-1fc0c161c5ad] in group console-consumer-875 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:50,628] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-875 in state PreparingRebalance with old generation 1 (__consumer_offsets-31) (reason: removing member consumer-console-consumer-875-1-751bf938-9e11-45ca-8818-1fc0c161c5ad on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:22:50,629] INFO [GroupCoordinator 0]: Group console-consumer-875 with generation 2 is now empty (__consumer_offsets-31) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:23:45,110] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-98509 in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-console-consumer-98509-1-971bf89e-7e94-44be-a64e-2d34e673f52e with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:23:45,111] INFO [GroupCoordinator 0]: Stabilized group console-consumer-98509 generation 1 (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:23:45,116] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-98509 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:02,802] INFO [GroupCoordinator 0]: Preparing to rebalance group 48b511c9-b073-4913-9084-81c78479a429 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member your_client_id2a1ec303-c82b-4f59-aaaf-f22cda271570-cb684743-0f43-4bac-b46f-47ac12263889 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:02,803] INFO [GroupCoordinator 0]: Stabilized group 48b511c9-b073-4913-9084-81c78479a429 generation 1 (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:02,806] INFO [GroupCoordinator 0]: Assignment received from leader for group 48b511c9-b073-4913-9084-81c78479a429 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:14,817] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-98509-1-971bf89e-7e94-44be-a64e-2d34e673f52e] in group console-consumer-98509 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:14,818] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-98509 in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-console-consumer-98509-1-971bf89e-7e94-44be-a64e-2d34e673f52e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:14,818] INFO [GroupCoordinator 0]: Group console-consumer-98509 with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:24,828] INFO [GroupCoordinator 0]: Member your_client_id2a1ec303-c82b-4f59-aaaf-f22cda271570-cb684743-0f43-4bac-b46f-47ac12263889 in group 48b511c9-b073-4913-9084-81c78479a429 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:24,828] INFO [GroupCoordinator 0]: Preparing to rebalance group 48b511c9-b073-4913-9084-81c78479a429 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: removing member your_client_id2a1ec303-c82b-4f59-aaaf-f22cda271570-cb684743-0f43-4bac-b46f-47ac12263889 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:24,828] INFO [GroupCoordinator 0]: Group 48b511c9-b073-4913-9084-81c78479a429 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:58,122] INFO [GroupCoordinator 0]: Preparing to rebalance group 3f0d100c-57d3-49e1-ba29-2677e812652a in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member your_client_id601edb16-4487-4acb-9c38-25ab172c6870-6ad4b66e-f844-49f7-a594-14e18efaf129 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:58,123] INFO [GroupCoordinator 0]: Stabilized group 3f0d100c-57d3-49e1-ba29-2677e812652a generation 1 (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:25:58,128] INFO [GroupCoordinator 0]: Assignment received from leader for group 3f0d100c-57d3-49e1-ba29-2677e812652a for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:26:16,026] INFO [GroupCoordinator 0]: Member your_client_id601edb16-4487-4acb-9c38-25ab172c6870-6ad4b66e-f844-49f7-a594-14e18efaf129 in group 3f0d100c-57d3-49e1-ba29-2677e812652a has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:26:16,026] INFO [GroupCoordinator 0]: Preparing to rebalance group 3f0d100c-57d3-49e1-ba29-2677e812652a in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: removing member your_client_id601edb16-4487-4acb-9c38-25ab172c6870-6ad4b66e-f844-49f7-a594-14e18efaf129 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:26:16,026] INFO [GroupCoordinator 0]: Group 3f0d100c-57d3-49e1-ba29-2677e812652a with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:27:06,303] INFO Creating topic W1a with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:27:06,307] INFO [KafkaApi-0] Auto creation of topic W1a with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:27:06,312] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1a-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:27:06,314] INFO [Log partition=W1a-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:27:06,314] INFO [Log partition=W1a-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 1 ms (kafka.log.Log)
[2020-03-26 17:27:06,315] INFO Created log for partition W1a-0 in /tmp/kafka-logs-0/W1a-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:27:06,316] INFO [Partition W1a-0 broker=0] No checkpointed highwatermark is found for partition W1a-0 (kafka.cluster.Partition)
[2020-03-26 17:27:06,316] INFO [Partition W1a-0 broker=0] Log loaded for partition W1a-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:27:06,316] INFO [Partition W1a-0 broker=0] W1a-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:32:02,805] INFO [GroupMetadataManager brokerId=0] Group console-consumer-98509 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:32:02,807] INFO [GroupMetadataManager brokerId=0] Group console-consumer-875 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:32:02,808] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 6 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:32:53,227] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-94257 in state PreparingRebalance with old generation 0 (__consumer_offsets-28) (reason: Adding new member consumer-console-consumer-94257-1-860479ff-2f51-4b83-8632-6aedca0544e8 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:32:53,228] INFO [GroupCoordinator 0]: Stabilized group console-consumer-94257 generation 1 (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:32:53,231] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-94257 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:32:55,712] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-94257-1-860479ff-2f51-4b83-8632-6aedca0544e8] in group console-consumer-94257 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:32:55,712] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-94257 in state PreparingRebalance with old generation 1 (__consumer_offsets-28) (reason: removing member consumer-console-consumer-94257-1-860479ff-2f51-4b83-8632-6aedca0544e8 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:32:55,712] INFO [GroupCoordinator 0]: Group console-consumer-94257 with generation 2 is now empty (__consumer_offsets-28) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:04,517] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-39460 in state PreparingRebalance with old generation 0 (__consumer_offsets-3) (reason: Adding new member consumer-console-consumer-39460-1-5a2847d2-e345-49fb-96c4-a4c00f1a67da with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:04,518] INFO [GroupCoordinator 0]: Stabilized group console-consumer-39460 generation 1 (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:04,522] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-39460 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:49,200] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 in state PreparingRebalance with old generation 0 (__consumer_offsets-7) (reason: Adding new member prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-8546018b-6ced-41c0-8b60-13fd8abab804-StreamThread-1-evaluation.consumer-e6f5e2fa-ea5d-41c3-8ac9-9feeefee6600 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:49,201] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 generation 1 (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:33:49,228] INFO Creating topic prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:33:49,239] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:33:49,240] INFO Creating topic prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:33:49,242] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:33:49,243] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:33:49,243] INFO Created log for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:33:49,244] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,244] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 broker=0] Log loaded for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,244] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 broker=0] prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_38a6fe01-9885-4848-a868-ea2eaf45d3c2-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:33:49,247] INFO Creating topic prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:33:49,249] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:33:49,252] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:33:49,252] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:33:49,253] INFO Created log for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:33:49,254] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,254] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 broker=0] Log loaded for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,254] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 broker=0] prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_85e72510-2352-49a3-99c1-2b0071964bc9-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:33:49,257] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:33:49,260] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:33:49,261] INFO [Log partition=prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:33:49,261] INFO Created log for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:33:49,262] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,262] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 broker=0] Log loaded for partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:33:49,262] INFO [Partition prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 broker=0] prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-_Store_eabdfc96-0efb-49e4-bf23-b3a2a2264b18-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:33:49,276] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:24,224] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-39460-1-5a2847d2-e345-49fb-96c4-a4c00f1a67da] in group console-consumer-39460 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:24,225] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-39460 in state PreparingRebalance with old generation 1 (__consumer_offsets-3) (reason: removing member consumer-console-consumer-39460-1-5a2847d2-e345-49fb-96c4-a4c00f1a67da on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:24,225] INFO [GroupCoordinator 0]: Group console-consumer-39460 with generation 2 is now empty (__consumer_offsets-3) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:26,612] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-45162 in state PreparingRebalance with old generation 0 (__consumer_offsets-29) (reason: Adding new member consumer-console-consumer-45162-1-94bf672c-7e83-4c3c-aa8f-650c04fa0e75 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:26,612] INFO [GroupCoordinator 0]: Stabilized group console-consumer-45162 generation 1 (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:26,618] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-45162 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:27,821] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-45162-1-94bf672c-7e83-4c3c-aa8f-650c04fa0e75] in group console-consumer-45162 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:27,822] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-45162 in state PreparingRebalance with old generation 1 (__consumer_offsets-29) (reason: removing member consumer-console-consumer-45162-1-94bf672c-7e83-4c3c-aa8f-650c04fa0e75 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:34:27,822] INFO [GroupCoordinator 0]: Group console-consumer-45162 with generation 2 is now empty (__consumer_offsets-29) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:25,450] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-33234 in state PreparingRebalance with old generation 0 (__consumer_offsets-46) (reason: Adding new member consumer-console-consumer-33234-1-43d36de7-ec40-463c-8f77-8cf45a9b1c92 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:25,450] INFO [GroupCoordinator 0]: Stabilized group console-consumer-33234 generation 1 (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:25,454] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-33234 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:27,528] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-33234-1-43d36de7-ec40-463c-8f77-8cf45a9b1c92] in group console-consumer-33234 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:27,528] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-33234 in state PreparingRebalance with old generation 1 (__consumer_offsets-46) (reason: removing member consumer-console-consumer-33234-1-43d36de7-ec40-463c-8f77-8cf45a9b1c92 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:35:27,528] INFO [GroupCoordinator 0]: Group console-consumer-33234 with generation 2 is now empty (__consumer_offsets-46) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:42:02,821] INFO [GroupMetadataManager brokerId=0] Group console-consumer-39460 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:42:02,822] INFO [GroupMetadataManager brokerId=0] Group console-consumer-45162 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:42:02,823] INFO [GroupMetadataManager brokerId=0] Group console-consumer-94257 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:42:02,823] INFO [GroupMetadataManager brokerId=0] Group console-consumer-33234 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:42:02,824] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 4 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:46:02,881] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-47592 in state PreparingRebalance with old generation 0 (__consumer_offsets-48) (reason: Adding new member consumer-console-consumer-47592-1-f5ccbcee-89ba-4779-8201-12cf390cab10 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:02,881] INFO [GroupCoordinator 0]: Stabilized group console-consumer-47592 generation 1 (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:02,885] INFO [GroupCoordinator 0]: Assignment received from leader for group console-consumer-47592 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:05,112] INFO [GroupCoordinator 0]: Member[group.instance.id None, member.id consumer-console-consumer-47592-1-f5ccbcee-89ba-4779-8201-12cf390cab10] in group console-consumer-47592 has left, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:05,112] INFO [GroupCoordinator 0]: Preparing to rebalance group console-consumer-47592 in state PreparingRebalance with old generation 1 (__consumer_offsets-48) (reason: removing member consumer-console-consumer-47592-1-f5ccbcee-89ba-4779-8201-12cf390cab10 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:05,112] INFO [GroupCoordinator 0]: Group console-consumer-47592 with generation 2 is now empty (__consumer_offsets-48) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:32,955] INFO [GroupCoordinator 0]: Member prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-8546018b-6ced-41c0-8b60-13fd8abab804-StreamThread-1-evaluation.consumer-e6f5e2fa-ea5d-41c3-8ac9-9feeefee6600 in group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:32,955] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 in state PreparingRebalance with old generation 1 (__consumer_offsets-7) (reason: removing member prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59-8546018b-6ced-41c0-8b60-13fd8abab804-StreamThread-1-evaluation.consumer-e6f5e2fa-ea5d-41c3-8ac9-9feeefee6600 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:46:32,955] INFO [GroupCoordinator 0]: Group prova_windowstore_27892278-f6be-48bc-90a3-3044d42dab59 with generation 2 is now empty (__consumer_offsets-7) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:52:02,821] INFO [GroupMetadataManager brokerId=0] Group console-consumer-47592 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:52:02,822] INFO [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds. (kafka.coordinator.group.GroupMetadataManager)
[2020-03-26 17:56:23,634] INFO Creating topic W1c with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:56:23,638] INFO [KafkaApi-0] Auto creation of topic W1c with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:56:23,649] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(W1c-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:56:23,652] INFO [Log partition=W1c-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:56:23,653] INFO [Log partition=W1c-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:56:23,653] INFO Created log for partition W1c-0 in /tmp/kafka-logs-0/W1c-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:56:23,654] INFO [Partition W1c-0 broker=0] No checkpointed highwatermark is found for partition W1c-0 (kafka.cluster.Partition)
[2020-03-26 17:56:23,654] INFO [Partition W1c-0 broker=0] Log loaded for partition W1c-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:56:23,654] INFO [Partition W1c-0 broker=0] W1c-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:57:45,400] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 in state PreparingRebalance with old generation 0 (__consumer_offsets-19) (reason: Adding new member prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-bb99f05f-b4b4-4a7e-b166-5bb5bcbeaee7-StreamThread-1-evaluation.consumer-30bd9559-ca2f-4f11-9849-3bf4944c58dc with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:57:45,400] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 generation 1 (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:57:45,415] INFO Creating topic prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:57:45,422] INFO Creating topic prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:57:45,426] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:57:45,429] INFO Creating topic prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:57:45,429] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:57:45,430] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 3 ms (kafka.log.Log)
[2020-03-26 17:57:45,430] INFO Created log for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:57:45,431] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,432] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 broker=0] Log loaded for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,432] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 broker=0] prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_288a8e5e-a4b0-4de7-baa5-516cc64404a1-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:57:45,436] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:57:45,439] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:57:45,440] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:57:45,440] INFO Created log for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:57:45,450] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,450] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 broker=0] Log loaded for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,451] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 broker=0] prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_2657b666-79c0-4482-aeb8-4ab928f10d4b-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:57:45,454] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:57:45,456] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:57:45,457] INFO [Log partition=prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:57:45,458] INFO Created log for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:57:45,458] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,458] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 broker=0] Log loaded for partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:57:45,458] INFO [Partition prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 broker=0] prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-_Store_adf1c7ee-fa43-4f63-86dc-8e5df3ca7694-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:57:45,468] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:11,105] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 in state PreparingRebalance with old generation 0 (__consumer_offsets-26) (reason: Adding new member prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-eb3a44ac-ab39-4341-b268-a2ffe0c17232-StreamThread-1-evaluation.consumer-ceb6d85d-9bd3-485f-8e54-25efb792fb43 with group instanceid None) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:11,106] INFO [GroupCoordinator 0]: Stabilized group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 generation 1 (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:11,118] INFO Creating topic prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:58:11,123] INFO Creating topic prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:58:11,125] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:58:11,127] INFO Creating topic prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog with configuration {cleanup.policy=compact} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:58:11,127] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:58:11,128] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:58:11,129] INFO Created log for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:58:11,129] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,129] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 broker=0] Log loaded for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,129] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 broker=0] prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_78668088-84df-461b-862d-8d087b482857-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:58:11,132] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:58:11,135] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:58:11,135] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:58:11,135] INFO Created log for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:58:11,136] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,136] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 broker=0] Log loaded for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,136] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 broker=0] prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_1d5ea2b2-74da-40c1-83b8-645f6671ead3-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:58:11,139] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:58:11,142] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:58:11,142] INFO [Log partition=prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:58:11,142] INFO Created log for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 in /tmp/kafka-logs-0/prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:58:11,143] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 broker=0] No checkpointed highwatermark is found for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,143] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 broker=0] Log loaded for partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,143] INFO [Partition prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 broker=0] prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-_Store_0dc6b607-140d-4bf6-ac39-66b1800f0677-changelog-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:58:11,151] INFO [GroupCoordinator 0]: Assignment received from leader for group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 for generation 1 (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:11,389] INFO Creating topic output_final with configuration {} and initial partition assignment Map(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2020-03-26 17:58:11,391] INFO [KafkaApi-0] Auto creation of topic output_final with 1 partitions and replication factor 1 is successful (kafka.server.KafkaApis)
[2020-03-26 17:58:11,395] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(output_final-0) (kafka.server.ReplicaFetcherManager)
[2020-03-26 17:58:11,397] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Loading producer state till offset 0 with message format version 2 (kafka.log.Log)
[2020-03-26 17:58:11,398] INFO [Log partition=output_final-0, dir=/tmp/kafka-logs-0] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms (kafka.log.Log)
[2020-03-26 17:58:11,398] INFO Created log for partition output_final-0 in /tmp/kafka-logs-0/output_final-0 with properties {compression.type -> producer, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.bytes -> 1073741824, retention.ms -> 604800000, flush.messages -> 9223372036854775807, message.format.version -> 2.4-IV1, file.delete.delay.ms -> 60000, max.compaction.lag.ms -> 9223372036854775807, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, segment.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760}. (kafka.log.LogManager)
[2020-03-26 17:58:11,398] INFO [Partition output_final-0 broker=0] No checkpointed highwatermark is found for partition output_final-0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,398] INFO [Partition output_final-0 broker=0] Log loaded for partition output_final-0 with initial high watermark 0 (kafka.cluster.Partition)
[2020-03-26 17:58:11,398] INFO [Partition output_final-0 broker=0] output_final-0 starts at leader epoch 0 from offset 0 with high watermark 0. Previous leader epoch was -1. (kafka.cluster.Partition)
[2020-03-26 17:58:16,493] INFO [GroupCoordinator 0]: Member prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-bb99f05f-b4b4-4a7e-b166-5bb5bcbeaee7-StreamThread-1-evaluation.consumer-30bd9559-ca2f-4f11-9849-3bf4944c58dc in group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:16,493] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 in state PreparingRebalance with old generation 1 (__consumer_offsets-19) (reason: removing member prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8-bb99f05f-b4b4-4a7e-b166-5bb5bcbeaee7-StreamThread-1-evaluation.consumer-30bd9559-ca2f-4f11-9849-3bf4944c58dc on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:16,493] INFO [GroupCoordinator 0]: Group prova_windowstore_fd58d6dd-d9ea-4475-9973-478d6ce943a8 with generation 2 is now empty (__consumer_offsets-19) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:21,153] INFO [GroupCoordinator 0]: Member prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-eb3a44ac-ab39-4341-b268-a2ffe0c17232-StreamThread-1-evaluation.consumer-ceb6d85d-9bd3-485f-8e54-25efb792fb43 in group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:21,153] INFO [GroupCoordinator 0]: Preparing to rebalance group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 in state PreparingRebalance with old generation 1 (__consumer_offsets-26) (reason: removing member prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0-eb3a44ac-ab39-4341-b268-a2ffe0c17232-StreamThread-1-evaluation.consumer-ceb6d85d-9bd3-485f-8e54-25efb792fb43 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2020-03-26 17:58:21,153] INFO [GroupCoordinator 0]: Group prova_windowstore_de7aa909-29f6-406f-a90f-4fa4d561aca0 with generation 2 is now empty (__consumer_offsets-26) (kafka.coordinator.group.GroupCoordinator)
